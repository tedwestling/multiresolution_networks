var(se.D[,1])
var(se.DC[,1])
var(se.DC[,2])
var(se.E[,2])
var(se.E[,3])
var(se.DC[,3])
var(se.Et[,3])
var(se.Et[,3],na.rm=T)
var(se.Et[,4])
var(se.Et[,4],na.rm=T)
var(se.DC[,4],na.rm=T)
var(se.DC[,4],na.rm=T)which
which(se.E>4)
?which
which(se.E>4,arr.ind=T)
beta.hat[2,]
beta.hat[3,]
beta.hat[4,]
beta.hat[18,]
beta.hat[5,]
which(p.e>4,arr.ind=T)[,1]
which(p.e>4,arr.ind=T)
which(se.E>4,arr.ind=T)
unique(which(se.E>4,arr.ind=T)[,1])
dim(p.e)
length(p.e)
dim(p.e)
issues<-unique(which(se.E>4,arr.ind=T)[,1])#
#now remove these problematic ones#
p.e[issues,]<-rep(NA,4)#
p.dc[issues,]<-rep(NA,4)
p.e[2,]
pdf( file=file.path(dir.out, paste('bymuni_allcoef_pval','pdf',sep='.')), width = 5, height = 5)#
par(mar = c(3, 3, 3, 3), mgp=c(2,.5,0), cex.lab=1.2, cex.axis=1.) #
x.range <- range(p.dc,na.rm=T)+.018#
y.range <- range(p.e,na.rm=T)+.018#
plot(p.e[,1]~p.dc[,1], cex=1.2, lwd=2, xlab="Dyadic clustering p-value", ylab="Exchangeable p-value", pch=16, col=col.vec[1], xlim=x.range, ylim=y.range)#
pchvec=c(16,17,3,4)#
for (i in 2:p.tot){#
  points(p.e[,i]~p.dc[,i], pch=pchvec[i], col=col.vec[i], cex=1.2, lwd=2)#
}#
abline(v=.05, lty=2)#
abline(h=.05, lty=2)#
abline(0,1, lty=3)#
legend(legend.loc, beta.names, pch = c(1:6), col=col.vec, #
       bty='n', horiz=F, cex = 1.1, pt.cex = 2*rep(1,6))#
dev.off()
pdf( file=file.path(dir.out, paste('bymuni_b1_pval','pdf',sep='.')), width = 5, height = 5)#
par(mar = c(3, 3, 3, 3), mgp=c(2,.5,0), cex.lab=1.2, cex.axis=1) #
x.range <- range(p.dc,na.rm=T)+.018#
y.range <- range(p.e,na.rm=T)+.018#
plot(p.e[,1]~p.dc[,1], cex=1.2, lwd=2, xlab="Dyadic clustering p-value", ylab="Exchangeable p-value", pch=16, col=col.vec[1], xlim=x.range, ylim=y.range,main="Intercept",cex.main=1.5)#
abline(v=.05, lty=2)#
abline(h=.05, lty=2)#
abline(0,1, lty=3)#
#legend(legend.loc, beta.names, pch = c(1:6), col=col.vec, #
 #      bty='n', horiz=F, cex = 1.1, pt.cex = 2*rep(1,6))#
dev.off()#
#
pdf( file=file.path(dir.out, paste('bymuni_b2_pval','pdf',sep='.')), width = 5, height = 5)#
par(mar = c(3, 3, 3, 3), mgp=c(2,.5,0), cex.lab=1.2, cex.axis=1) #
x.range <- range(p.dc,na.rm=T)+.018#
y.range <- range(p.e,na.rm=T)+.018#
plot(p.e[,2]~p.dc[,2], cex=1.2, lwd=2, xlab="Dyadic clustering p-value", ylab="Exchangeable p-value", pch=17, col=col.vec[2], xlim=x.range, ylim=y.range,main="Difference in risk preference",cex.main=1.5)#
abline(v=.05, lty=2)#
abline(h=.05, lty=2)#
abline(0,1, lty=3)#
#legend(legend.loc, beta.names, pch = c(1:6), col=col.vec, #
#       bty='n', horiz=F, cex = 1.1, pt.cex = 2*rep(1,6))#
dev.off()#
pdf( file=file.path(dir.out, paste('bymuni_b3_pval','pdf',sep='.')), width = 5, height = 5)#
par(mar = c(3, 3, 3, 3), mgp=c(2,.5,0), cex.lab=1.2, cex.axis=1) #
x.range <- range(p.dc,na.rm=T)+.018#
y.range <- range(p.e,na.rm=T)+.018#
plot(p.e[,3]~p.dc[,3], cex=1.2, lwd=2, xlab="Dyadic clustering p-value", ylab="Exchangeable p-value", pch=3, col=col.vec[3], xlim=x.range, ylim=y.range,main="Family/Friend",cex.main=1.5)#
abline(v=.05, lty=2)#
abline(h=.05, lty=2)#
abline(0,1, lty=3)#
#legend(legend.loc, beta.names, pch = c(1:6), col=col.vec, #
  #     bty='n', horiz=F, cex = 1.1, pt.cex = 2*rep(1,6))#
dev.off()#
pdf( file=file.path(dir.out, paste('bymuni_b4_pval','pdf',sep='.')), width = 5, height = 5)#
par(mar = c(3, 3, 3, 3), mgp=c(2,.5,0), cex.lab=1.2, cex.axis=1) #
x.range <- range(p.dc,na.rm=T)+.018#
y.range <- range(p.e,na.rm=T)+.018#
plot(p.e[,4]~p.dc[,4], cex=1.2, lwd=2, xlab="Dyadic clustering p-value", ylab="Exchangeable p-value", pch=4, col=col.vec[4], xlim=x.range, ylim=y.range,main="Interaction",cex.main=1.5)#
abline(v=.05, lty=2)#
abline(h=.05, lty=2)#
abline(0,1, lty=3)#
#legend(legend.loc, beta.names, pch = c(1:6), col=col.vec, #
 #      bty='n', horiz=F, cex = 1.1, pt.cex = 2*rep(1,6))#
dev.off()
se.Et=se.E#
se.Et[issues,]<-rep(NA,4)#
se.DCt=se.DC#
se.DCt[issues,]<-rep(NA,4)
var(se.Et[,1],na.rm=T)
var(se.DCt[,1],na.rm=T)
var(se.DCt[,2],na.rm=T)
var(se.Et[,2],na.rm=T)
var(se.Et[,3],na.rm=T)
var(se.DCt[,3],na.rm=T)
var(se.Et[,4],na.rm=T)
var(se.DCt[,4],na.rm=T)
boxplot(cbind(se.Et[,1],se.DCt[,1],se.Et[,2],se.DCt[,2],se.Et[,3],se.DCt[,3],se.Et[,4],se.DCt[,4]))
which.max(se.Et,arr.ind=T)
which(max(se.Et,na.rm=T),arr.ind=T)
max(se.Et,na.rm=T)
which(se.Et>3.66,arr.ind=T)
adata
adata=read.csv("/Users/tylermccormick/Dropbox/netreg_villages/AEJApp-2010-0118data/AttanasioEtAl2011Dyadic_processed.csv")#
source("/Users/tylermccormick/Dropbox/netreg_villages/160128_function_file_india_tm.R")
adata=read.csv("/Users/tylermccormick/Dropbox/netreg_villages/AEJApp-2010-0118data/AttanasioEtAl2011Dyadic_processed.csv")
Yin=Yin[which(adata$municode==13)]#
Xin=Xin[which(adata$municode==13),]
aglm=glm(samegroup~difchoice1+frfamcl+dcfrfamcl,data=adata,family=binomial("logit"))#
Xin=model.matrix(aglm)#
Yin=adata$samegroup#
Yin=Yin[which(adata$municode==13)]#
Xin=Xin[which(adata$municode==13),]
dim(Xin)
dim(Yin)
length(Yin)
gfit=glm(Yin~Xin-1,family=binomial(link="logit"))
gfit
summary(gfit)
se.Et[13,]
se.DC[13,]
colSums(se.Et-s.DCt,na.rm=T)
colSums(se.Et-se.DCt,na.rm=T)
colSums(se.Et,na.rm=T)
colSums(se.DCt,na.rm=T)
boxplot(se.Et[,1]-se.DCt[,1],se.Et[,2]-se.DCt[,2])
,se.Et[,2]-se.DCt[,2]
boxplot(se.Et[,1]-se.DCt[,1],se.Et[,2]-se.DCt[,2],se.Et[,3]-se.DCt[,3],se.Et[,4]-se.DCt[,4])
abline(h=0,col='red')
boxplot((se.Et[,1]-se.DCt[,1])/se.DCt[,1],se.Et[,2]-se.DCt[,2],se.Et[,3]-se.DCt[,3],se.Et[,4]-se.DCt[,4])
boxplot((se.Et[,1]-se.DCt[,1])/se.DCt[,1],(se.Et[,2]-se.DCt[,2])/se.DCt[,2],(se.Et[,3]-se.DCt[,3])/se.DCt[,3],(se.Et[,4]-se.DCt[,4])/se.DCt[,4])
abline(h=0,col="red")
summary(se.Et[,1])
summary(se.DCt[,1])
?boxplot
boxplot((se.Et[,1]-se.DCt[,1])/se.DCt[,1],(se.Et[,2]-se.DCt[,2])/se.DCt[,2],(se.Et[,3]-se.DCt[,3])/se.DCt[,3],(se.Et[,4]-se.DCt[,4])/se.DCt[,4],names=c("Intercept","Risk preferences","Family/friend","Interaction"),main="Exchangeable SE-Dyad SE/Dyad SE")
pdf( file=file.path(dir.out, paste('difbp','pdf',sep='.')), width = 8, height = 5)#
boxplot((se.Et[,1]-se.DCt[,1])/se.DCt[,1],(se.Et[,2]-se.DCt[,2])/se.DCt[,2],(se.Et[,3]-se.DCt[,3])/se.DCt[,3],(se.Et[,4]-se.DCt[,4])/se.DCt[,4],names=c("Intercept","Risk preferences","Family/friend","Interaction"),main="(Exchangeable SE-Dyad SE)/Dyad SE")#
abline(h=0,col='red')#
dev.off()
head(X.in)
head(Xin)
Xin[,3]
sum(Xin[,3])
dim(Xin)
sum(Se.Et>3)
Yin[Xin[,3]==1]
sum(Yin[Xin[,3]==1])
sum(Yin)
sum(se.Et>3)
sum(se.Et>3,na.rm=T)
sum(se.Et>2,na.rm=T)
sum(se.Et>1.5,na.rm=T)
sum(se.Et>1.2,na.rm=T)
sum(se.Et>1,na.rm=T)
sum(se.DCt>1,na.rm=T)
sum(se.DCt>.75,na.rm=T)
sum(se.Et>.75,na.rm=T)
library(InterVa)
library(InterVA4)
library(InterVa4)
install.packages("InterVA4")
?InterVA4
??InterVA4
help(interva)
??interva
library(InterVA4)
intsall.packages("InSilicoVA")
install.packages("InSilicoVA")
library(InSilicoVA)
library(InterVA4)
library(InSilicoVA)
?InSilicoVA
??InSilicoVA
?insilico
?interva
?interva4
?interVA
??interVA
library(foreign)#
library(arm)#
wdata=read.dta("/Users/tylermccormick/Dropbox/garment workers and garment factories/garments data monthly wage observations with grievances.dta")
names(wdata)
facconditions=tapply(wdata$goodconditions,wdata$factory,mean)
length(facconditions)
wdata$fromurban
wdata$fromurban[wdata$hr21==26|wdata$hr21==33]<-1
fconditions=tapply(wdata$goodconditions,wdata$factory,mean)
facconditions=rep(NA,nrow(wdata))
fconditions=tapply(wdata$goodconditions,wdata$factory,mean)
table(wdata$factory)
length(table(wdata$factory))
names(table(wdata$factory))
a=match(wdata$factory,names(table(wdata$factory)))
length(a)
a[1:10]
max(a)
for(ii in 1:length(facconditions)){facconditions[ii]<-fconditions[match(wdata$factory,names(table(wdata$factory)))[ii]]}
for(ii in 1:length(facconditions)){facconditions[ii]<-mean(wdata$goodconditions[wdata$factory==ii])}
lm1<-lm(facconditions~wdata$migrant)
lm1<-lm(facconditions~migrant)
ls()
migrant=wdata$fromurban
migrant[wdata$hr21==26|wdata$hr21==33]<-1
lm1<-lm(facconditions~migrant)
lm1
summary(lm1)
sum(is.na(faconditions))
sum(is.na(facconditions))
library(foreign)#
library(arm)#
wdata=read.dta("/Users/tylermccormick/Dropbox/garment workers and garment factories/garments data monthly wage observations with grievances.dta")
facconditions=rep(NA,nrow(wdata))
ii=1
mean(wdata$goodconditions[wdata$factory==ii])
for(ii in 1:length(facconditions)){facconditions[ii]<-mean(wdata$goodconditions[wdata$factory==ii],na.rm=T)}
sum(is.na(facconditions))
sum(is.na(wdata$goodconditions))
sum(is.na(wdata$factory))
head(facconditions)
ii=2
ii=3
mean(wdata$goodconditions[wdata$factory==ii],na.rm=T)
mean(wdata$goodconditions[wdata$factory==wdata$factory[ii]])
mean(wdata$goodconditions[wdata$factory==wdata$factory[ii]],na.rm=T)
wdata$goodconditions[wdata$factory==wdata$factory[ii]]
for(ii in 1:length(facconditions)){facconditions[ii]<-mean(wdata$goodconditions[wdata$factory==wdata$factory[ii]])}
sum(is.na(facconditions))
for(ii in 1:length(facconditions)){facconditions[ii]<-mean(wdata$goodconditions[wdata$factory==wdata$factory[ii]],na.rm=T)}
sum(is.na(facconditions))
migrant=wdata$fromurban#
migrant[wdata$hr21==26|wdata$hr21==33]<-1#
#
lm1<-lm(facconditions~migrant)
lm1
summary(lm1)
migrant=wdata$fromurban#
migrant[wdata$hr21==26|wdata$hr21==33]<-1#
#
lm2<-lm(facconditions~migrant+wdata$male)
summary(lm2)
d.tot <- n.tot*(n.tot-1)/2*(1 + dir.ind)
dim(migrant)
length(migrant)
levels(migrant)
head(migrant)
max(migrant)
min(migrant,na.rm=T)
max(migrant,na.rm=T)
migrant<-migrant*-1#
#
lm1<-lm(facconditions~migrant)
lm1
summary(lm1)
attach(wdata)#
varmat=cbind(reldum1,reldum2,reldum3,reldum4,invpA,invpB,invpC,#
             invpD,invpE,invpF,invpG,invpZ,medcare,apptletter)#
gnames=c("reldum1","reldum2","reldum3","reldum4","invpA","invpB","invpC",#
         "invpD","invpE","invpF","invpG","invpZ","medcare","apptletter")
ls()
names(wdata)
varmat=cbind(reldum1,reldum2,reldum3,reldum4,invpA,invpC,#
             invpD,invpE,invpF,invpG,invpZ,medcare,apptletter)
gnames=c("reldum1","reldum2","reldum3","reldum4","invpA","invpC",#
         "invpD","invpE","invpF","invpG","invpZ","medcare","apptletter")
dim(medcare)
length(medcare)
max(medcare, na.rm=T)
min(medcare, na.rm=T)
mcconditions=rep(NA,nrow(wdata))#
for(ii in 1:length(facconditions)){mcconditions[ii]<-mean(wdata$medcare[wdata$factory==wdata$factory[ii]],na.rm=T)}
mclm=glm(mcconditions~migrant,family=binomial)
glm(mcconditions~migrant)
apconditions=rep(NA,nrow(wdata))#
for(ii in 1:length(facconditions)){apconditions[ii]<-mean(wdata$apptletter[wdata$factory==wdata$factory[ii]],na.rm=T)}#
#
aplm=glm(apconditions~migrant)
aplm
dnb <- function(y, lambda, alpha){#
    dnbinom(y, size=alpha, mu=lambda, log=T)#
  }#
#
pnb <- function(cut, lambda, alpha){#
  sum <-0#
  pnbinom(cut, size=alpha, mu=lambda, lower.tail=F, log.p=T)                                       #
}#
#
ll.ztnb.bs.IM <- function(theta, y, X, alpha, cut){#
  lambda <- exp(drop(X %*% theta))#
  zeros <- log(1-pnb(cut, lambda, alpha))#
  -(dnb(y, lambda, alpha) - zeros)#
}#
#
ztnb <- function(par, y, X, cut){#
  end <- (length(par))-1#
  theta <- par[1:end]#
  alpha <- exp(par[length(par)])#
  lambda <- exp(drop(X %*% theta))#
  zeros <- pnb(cut, lambda,alpha)#
  ll <- sum(dnb(y, lambda, alpha) - zeros)#
  return(ll)#
}
bootstrapIM.ztnb <- function(formula, X, data, B,B2){#
  y <- data[,c(paste(formula[[2]]))]#
  out <- optim(c(rep(.01,ncol(X)),.01), ztnb, y=y, X=X,cut=4.1,control=list(fnscale=-1,maxit=10000), method="BFGS", hessian=T)#
  ok <- !is.na(out$par)#
  theta <- out$par[ok][-length(out$par[ok])]#
  alpha <- exp(out$par[ok][length(out$par[ok])])#
  lambda <- exp(drop(X%*%theta))#
  grad <- apply(cbind(y,X),1,function(x) numericGradient(ll.ztnb.bs.IM, theta, y=x[1], X=x[2:length(x)], alpha=alpha, cut=4.1))#
  meat <- grad%*%t(grad)#
  bread <- out$hessian[ok,ok][1:(length(out$par[ok])-1),1:(length(out$par[ok])-1)]#
  Dhat <- diag(nrow(X)^(-1/2)*(meat + bread))[1:7]  #
  D <- list()#
  Dbar <- rep(0, length(Dhat))#
  for(i in 1:B){#
    yB <- rnegbin(nrow(data), lambda, alpha)#
    print(length(yB[yB<5]))#
    while(length(yB[yB<5])>0){#
      yB[yB<5] <- rnegbin(length(yB[yB<5]), lambda, alpha)#
    }#
    XB <- X[!is.na(yB),]#
    yB <- yB[!is.na(yB)]#
    outB <- optim(c(rep(.01,ncol(XB)),.01), ztnb, y=yB, X=XB,cut=4.1,control=list(fnscale=-1,maxit=10000), method="BFGS", hessian=T)#
    ok <- !is.na(out$par)#
    thetaB <- outB$par[ok][-length(outB$par[ok])]#
    alphaB <- exp(outB$par[ok][length(outB$par[ok])])#
    grad <- apply(cbind(yB,XB),1,function(x) numericGradient(ll.ztnb.bs.IM, thetaB, y=x[1], X=x[2:length(x)], alpha=alphaB, cut=4.1))#
    meat <- grad%*%t(grad)#
    bread <- outB$hessian[ok,ok][1:(length(outB$par[ok])-1),1:(length(outB$par[ok])-1)]#
    D[[i]] <- diag(nrow(XB)^(-1/2)*(meat + bread))[1:7]#
    Dbar <- D[[i]] + Dbar#
    DBbar <- rep(0, length(Dhat))#
    DB <- list()#
    for(j in 1:B2){#
      yB2 <- rnegbin(nrow(data), lambda, alpha)#
      while(length(yB2[yB2<5])>0){#
        yB2[yB2<5] <- rnegbin(length(yB2[yB2<5]), lambda, alpha)#
      }#
#
      XB2 <- X[!is.na(yB2),]#
      yB2 <- yB2[!is.na(yB2)]#
      outB2 <- optim(c(rep(.01,ncol(XB2)),.01), ztnb, y=yB2, X=XB2,cut=4.1,control=list(fnscale=-1,maxit=10000), method="BFGS", hessian=T)#
      ok <- !is.na(outB2$par)#
      thetaB2 <- outB2$par[ok][-length(outB2$par[ok])]#
      alphaB2 <- exp(outB2$par[ok][length(outB2$par[ok])])#
      grad <- apply(cbind(yB2,XB2),1,function(x) numericGradient(ll.ztnb.bs.IM, thetaB2, y=x[1], X=x[2:length(x)], alpha=alphaB2, cut=4.1))#
      meat <- grad%*%t(grad)#
      bread <- outB2$hessian[ok,ok][1:(length(outB2$par[ok])-1),1:(length(outB2$par[ok])-1)]#
      DB[[j]] <- diag(nrow(XB2)^(-1/2)*(meat + bread))[1:7]#
#
      DBbar <- DB[[j]] + DBbar#
    }#
    DBbar <- DBbar/B2#
    VBb <- matrix(0, nrow=length(DBbar), ncol=length(DBbar))#
    for(j in 1:B2){#
      VBb <- VBb + (DB[[j]] - DBbar)%*%t(DB[[j]]-DBbar)#
    }#
    VBb <- VBb/(B2-1)#
    #invVBb <- invcov.shrink(VBb)#
    invVBb <- solve(VBb)#
    T[i] <- t(D[[i]])%*%invVBb%*%D[[i]]#
    print(i)#
    print(T[i])#
    if(i%%10==0) print(i)#
  }#
  Dbar <- Dbar/B#
#
  Vb <- matrix(0, nrow=length(Dbar), ncol=length(Dbar))#
  for(i in 1:B){#
    Vb <- Vb + (D[[i]] - Dbar)%*%t(D[[i]]-Dbar)#
  }#
  Vb <- Vb/(B-1)#
  #invVb <- invcov.shrink(Vb)#
  invVb <- solve(Vb)#
#
  omegaB <- t(Dhat)%*%invVb%*%Dhat#
  print("omegaB")#
  print(omegaB)#
  pb = (B+1-sum(T< as.numeric(omegaB)))/(B+1)#
#
  return(list(stat=omegaB, pval=pb))#
}
dnb <- function(y, lambda, alpha){#
    dnbinom(y, size=alpha, mu=lambda, log=T)#
  }#
#
pnb <- function(cut, lambda, alpha){#
  sum <-0#
  pnbinom(cut, size=alpha, mu=lambda, lower.tail=F, log.p=T)                                       #
}#
#
ll.ztnb.bs.IM <- function(theta, y, X, alpha, cut){#
  lambda <- exp(drop(X %*% theta))#
  zeros <- log(1-pnb(cut, lambda, alpha))#
  -(dnb(y, lambda, alpha) - zeros)#
}#
#
ztnb <- function(par, y, X, cut){#
  end <- (length(par))-1#
  theta <- par[1:end]#
  alpha <- exp(par[length(par)])#
  lambda <- exp(drop(X %*% theta))#
  zeros <- pnb(cut, lambda,alpha)#
  ll <- sum(dnb(y, lambda, alpha) - zeros)#
  return(ll)#
}#
#
bootstrapIM.ztnb <- function(formula, X, data, B,B2){#
  y <- data[,c(paste(formula[[2]]))]#
  out <- optim(c(rep(.01,ncol(X)),.01), ztnb, y=y, X=X,cut=4.1,control=list(fnscale=-1,maxit=10000), method="BFGS", hessian=T)#
  ok <- !is.na(out$par)#
  theta <- out$par[ok][-length(out$par[ok])]#
  alpha <- exp(out$par[ok][length(out$par[ok])])#
  lambda <- exp(drop(X%*%theta))#
  grad <- apply(cbind(y,X),1,function(x) numericGradient(ll.ztnb.bs.IM, theta, y=x[1], X=x[2:length(x)], alpha=alpha, cut=4.1))#
  meat <- grad%*%t(grad)#
  bread <- out$hessian[ok,ok][1:(length(out$par[ok])-1),1:(length(out$par[ok])-1)]#
  Dhat <- diag(nrow(X)^(-1/2)*(meat + bread))[1:7]  #
  D <- list()#
  Dbar <- rep(0, length(Dhat))#
  for(i in 1:B){#
    yB <- rnegbin(nrow(data), lambda, alpha)#
    print(length(yB[yB<5]))#
    while(length(yB[yB<5])>0){#
      yB[yB<5] <- rnegbin(length(yB[yB<5]), lambda, alpha)#
    }#
    XB <- X[!is.na(yB),]#
    yB <- yB[!is.na(yB)]#
    outB <- optim(c(rep(.01,ncol(XB)),.01), ztnb, y=yB, X=XB,cut=4.1,control=list(fnscale=-1,maxit=10000), method="BFGS", hessian=T)#
    ok <- !is.na(out$par)#
    thetaB <- outB$par[ok][-length(outB$par[ok])]#
    alphaB <- exp(outB$par[ok][length(outB$par[ok])])#
    grad <- apply(cbind(yB,XB),1,function(x) numericGradient(ll.ztnb.bs.IM, thetaB, y=x[1], X=x[2:length(x)], alpha=alphaB, cut=4.1))#
    meat <- grad%*%t(grad)#
    bread <- outB$hessian[ok,ok][1:(length(outB$par[ok])-1),1:(length(outB$par[ok])-1)]#
    D[[i]] <- diag(nrow(XB)^(-1/2)*(meat + bread))[1:7]#
    Dbar <- D[[i]] + Dbar#
    DBbar <- rep(0, length(Dhat))#
    DB <- list()#
    for(j in 1:B2){#
      yB2 <- rnegbin(nrow(data), lambda, alpha)#
      while(length(yB2[yB2<5])>0){#
        yB2[yB2<5] <- rnegbin(length(yB2[yB2<5]), lambda, alpha)#
      }#
#
      XB2 <- X[!is.na(yB2),]#
      yB2 <- yB2[!is.na(yB2)]#
      outB2 <- optim(c(rep(.01,ncol(XB2)),.01), ztnb, y=yB2, X=XB2,cut=4.1,control=list(fnscale=-1,maxit=10000), method="BFGS", hessian=T)#
      ok <- !is.na(outB2$par)#
      thetaB2 <- outB2$par[ok][-length(outB2$par[ok])]#
      alphaB2 <- exp(outB2$par[ok][length(outB2$par[ok])])#
      grad <- apply(cbind(yB2,XB2),1,function(x) numericGradient(ll.ztnb.bs.IM, thetaB2, y=x[1], X=x[2:length(x)], alpha=alphaB2, cut=4.1))#
      meat <- grad%*%t(grad)#
      bread <- outB2$hessian[ok,ok][1:(length(outB2$par[ok])-1),1:(length(outB2$par[ok])-1)]#
      DB[[j]] <- diag(nrow(XB2)^(-1/2)*(meat + bread))[1:7]#
#
      DBbar <- DB[[j]] + DBbar#
    }#
    DBbar <- DBbar/B2#
    VBb <- matrix(0, nrow=length(DBbar), ncol=length(DBbar))#
    for(j in 1:B2){#
      VBb <- VBb + (DB[[j]] - DBbar)%*%t(DB[[j]]-DBbar)#
    }#
    VBb <- VBb/(B2-1)#
    #invVBb <- invcov.shrink(VBb)#
    invVBb <- solve(VBb)#
    T[i] <- t(D[[i]])%*%invVBb%*%D[[i]]#
    print(i)#
    print(T[i])#
    if(i%%10==0) print(i)#
  }#
  Dbar <- Dbar/B#
#
  Vb <- matrix(0, nrow=length(Dbar), ncol=length(Dbar))#
  for(i in 1:B){#
    Vb <- Vb + (D[[i]] - Dbar)%*%t(D[[i]]-Dbar)#
  }#
  Vb <- Vb/(B-1)#
  #invVb <- invcov.shrink(Vb)#
  invVb <- solve(Vb)#
#
  omegaB <- t(Dhat)%*%invVb%*%Dhat#
  print("omegaB")#
  print(omegaB)#
  pb = (B+1-sum(T< as.numeric(omegaB)))/(B+1)#
#
  return(list(stat=omegaB, pval=pb))#
}
dat <- read.dta("/Users/tylermccormick/Downloads/Article for ISQ (aid).dta")
remove(list=ls())#
library(foreign)#
library(mvtnorm)#
library(sandwich)#
library(lmtest)#
library(MASS)#
library(maxLik)#
library(xtable)
install.packages("maxLik")
source("/Users/tylermccormick/Downloads/bootstrapIM.normal.R")
#Read in data#
#############################################
dat <- read.dta("/Users/tylermccormick/Downloads/Article for ISQ (aid).dta")#
dat <- na.omit(dat[,c("multish", "lnpop", "lnpopsq", "lngdp", "lncolony", "lndist", "freedom", "militexp", "arms", "year83", "year86", "year89", "year92")])
#Replicate Neumayer#
#############################################
lm1 <- lm(multish ~ lnpop + lnpopsq + lngdp +  lncolony + lndist + freedom +militexp + arms + year83 + year86 + year89 + year92, data=dat)#
summary(lm1)#
n <- nrow(model.matrix(lm1))#
k <- ncol(model.matrix(lm1))#
coeftest(lm1, n/(n-k)*sandwich(lm1))
#Parametric bootstrap for first equation#
#############################################
B <- 1000#
formula <- multish ~ lnpop + lnpopsq + lngdp +  lncolony + lndist + freedom +militexp + arms + year86 + year89 + year92 #
data <- dat#
set.seed(02138)#
lm1IM <- bootstrapIM.normal(formula, dat, 99,50)#
#lm1IM p-value .019
source("/Users/tylermccormick/Downloads/bootstrapIM.normal.R")
lm1IM <- bootstrapIM.normal(formula, dat, 99,50)
library(maxLik)
lm1IM <- bootstrapIM.normal(formula, dat, 99,50)
?dbinom
pbinom(.8,3000,.16)
pbinom(.8,300,.16)
pbinom(.8,30,.16)
1-dbinom(0,3000,.16)
1-dbinom(0,300,.16)
1-dbinom(0,30,.16)
1-.16^10
1-.16^(30)
#july 1 2016#
  #this file takes in the necessary csv files with summary stats for each boxplot and actually #
  #creates the files that go into the paper#
  #note that we no longer need to do preprocessing bc the key stats are saved in the csv files in this directory#
# coverage.prob.tmp<-read.csv("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/coverageprob_n20.csv",header=F) #
#
# coverage.prob=array(dim=c(5,dim(coverage.prob.tmp))) #
# coverage.prob[1,,]<-read.csv("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/coverageprob_n20.csv",header=F) #
# coverage.prob[2,,]<-read.csv("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/coverageprob_n40.csv",header=F) #
# coverage.prob[3,,]<-read.csv("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/coverageprob_n80.csv",header=F) #
# coverage.prob[4,,]<-read.csv("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/coverageprob_n160.csv",header=F) #
# coverage.prob[5,,]<-read.csv("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/coverageprob_n320.csv",header=F) #
#
load("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
   # Boxplots/95% CI plots#
    # Boxplots of variances#
    legend.loc <- rep("topright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
    col.vec <- c('#2c7bb6', '#d7191c', '#fdae61')#
      #fdae61#
      #ffffbf#
      #abd9e9#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e <- .25                               # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
 out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
out.post <- paste(out.post,file.post,sep='')#
n.names <- N.test  #c('n = 10',N.test[2:length(N.test)])#
#
# col.vec <- c('#8da0cb', '#fc8d62', '#66c2a5')#
col.vec <- c('#d7191c', '#8da0cb', '#fdae61')#
#
legend.loc <- rep("bottomright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
nn  <- 5   # number of data series#
# Boxplots#
#if (model=='rand'){#
  for (i in 1:p.tot){#
    y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    name <- paste('CP2_se_',i,sep='')#
    name.file <- paste(out.post, name, sep="_")#
    plot.wd <- 4    # + .3*(i==1) #
    pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    if(i==1){#
      y.name.2 <- 'Non-Exchangeable Errors'#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    } else {#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    }#
    blw <- 2   # box line width#
    seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    y.range <- range(coverage.prob[,,seq.plots[1:3]], na.rm=T)#
    y.range[2] <- 1.00#
    y.range[1] <- .23  #max(y.range[1],50)#
    coverage.prob.1 <- coverage.prob/100#
    #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    	####Random error plots#
	####Random error plots#
	####Random error plots#
	####Random error plots#
	####Random error plots#
	####Random error plots#
    boxplot(t(coverage.prob.1[,,seq.plots[1]]), ylab="Coverage", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    boxplot(t(coverage.prob.1[,,seq.plots[2]]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    boxplot(t(coverage.prob.1[,,seq.plots[3]]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    if (i == 3) { #
      legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             col = c(col.vec, 'black'), #
             bty='n', horiz=F, cex = 1.)#
    }#
    #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    abline(h=.95,col='black',lty=2, lwd=1.5)#
    axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#     #
    dev.off()#
  }#
# #} else{   #
	# ######all the other plots#
# #  for (i in 1:p.tot){#
    # y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    # name <- paste('CP2_se_',i,sep='')#
    # name.file <- paste(out.post, name, sep="_")#
    # pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    # #plot.wd <- 4    #+ .3*(i==1) #
    # pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    # if(i==1){#
      # if (model=='iid'){#
        # y.name.2 <- 'IID Errors'#
      # } else {#
        # y.name.2 <- 'Exchangeable Errors'#
      # }#
	# par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    # } else {#
      # par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    # }#
    # blw <- 2   # box line width  blw <- 2   # box line width#
    # seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    # y.range <- range(coverage.prob[,,seq.plots[1:3]], na.rm=T)#
    # y.range[2] <- 1.00#
    # y.range[1] <- .23  #max(y.range[1],50)#
    # coverage.prob.1 <- coverage.prob/100#
    # #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    # boxplot(t(coverage.prob.1[,,seq.plots[1]]), ylab="Coverage", xlab="", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            # ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    # boxplot(t(coverage.prob.1[,,seq.plots[2]]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            # border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    # boxplot(t(coverage.prob.1[,,seq.plots[3]]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            # at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    # if (i == 3) { #
      # legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             # col = c(col.vec, 'black'), #
             # bty='n', horiz=F, cex = 1.0)#
    # }#
    # #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    # abline(h=.95,col='black',lty=2, lwd=1.5)#
       # axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    # title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#
# #     #
#
    # dev.off()#
  # }#
# ##}#
}
p.tot
dim(coverage.prob)
seq.plots
##
##this file prepares the output csv files necessary to plot the coverages#
#the make_figures file actually plots them and shoudl work as a stand-alone using what's in this #
#directory as inputs#
##
print("updated file")#
#
# INPUTS#
# File management #
data.in.name <- "Data_c_ols_4_corrected"        # name for data directory#
data.out.name <- "Plots_20_320"                 # name for plot directory#
file.post <- "_c_ols_4_SE"                      # post name for files to read in#
file.post.160 <- "_c_ols_SE"                    # postscript for files > 160 (naming was different at times)#
#setwd("~/Documents/work_R/Sandwich/paper_bv/Data_c_ols_4")     # set working directory, under which all files are assumed to be located#
#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e.test <- c(.25)                                # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
##not post processed#
#iid 160 1#
#
# Create directories#
dir.in <- '~/Dropbox/netreg_cluster/post_processed/'#file.path(getwd(),data.in.name)         # data input directory#
dir.out  <- '~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/figures' #file.path(getwd(),data.out.name)      # plot output directory#
#dir.create(file.path(getwd(),data.out.name))#
#
start.time <- proc.time()                         # start time#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
  for (f.loop in 1:length(f.e.test)) {#
    f.e <- f.e.test[f.loop]#
    # Build data#
    se.SE <- matrix(0, length(N.test), 4*p.tot)           # undconditional standard error of data #
    mean.SE  <- matrix(0, length(N.test), 4*p.tot)        # undconditional expectation error of data#
    se.true <- matrix(0, length(N.test), p.tot)           # estimates of true standard error#
    se.box <- array(0, c(length(N.test), 5, 3*p.tot))     # boxplot 5# summaries#
    var.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    mean.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    bias.SE.N.X <- array(0,c(length(N.test),X.test,3*p.tot))#
    se.emp.N.X <-  array(0,c(length(N.test),X.test,3*p.tot))     # S, U, HC empirical standard errors#
    coverage.prob <- array(0,c(length(N.test),X.test,3*p.tot,length(Model.test)))#
    for (n.loop in 1:length(N.test)) {#
      n.tot <- N.test[n.loop]     # number of members#
      d.tot <- n.tot*(n.tot-1)    # number of dyads in directed setting#
      for (x.loop in 1:X.test) {#
        if (n.tot<100){ #
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        } else {#
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post.160,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        #}}#
        }#
        # Read in data and eliminate extreme outliers#
        data.plot <- read.table(file= in.file, header=T)#
        if(remove.outlier == T) { #
          i.outlier <- which(abs(data.plot) > 1000, arr.ind=T)#
          data.plot[i.outlier[,1],] <- NA#
        }#
#
        var.SE.N.X[n.loop,x.loop,] <-apply(data.plot[,1:(4*p.tot)],2,var, na.rm=T)#
        mean.SE.N.X[n.loop,x.loop,] <- apply(data.plot[,1:(4*p.tot)],2,mean, na.rm=T)#
        beta.hat.in <- data.plot[,1:p.tot] #
        beta.true <- outer(rep(1,Rep.test),beta.1)#
        # Post process empirical variances and MSEs#
        for (i in 1:p.tot) {#
#           i.store = i.mat[i,1];   #
#           j.store = i.mat[i,2];#
          # empirical variance#
#           V.emp.N.X[n.loop,x.loop,i] = cov(beta.hat.in[i.store], beta.hat.in[j.store]);#
          se.emp.N.X[n.loop,x.loop,i] = sqrt(var(beta.hat.in[,i]) )#
          seq.p <- p.tot + rep(i,3) + c(0,1,2)*p.tot#
          UB.beta <- beta.hat.in[,i] + 1.96*data.plot[,seq.p]#
          LB.beta <- beta.hat.in[,i] - 1.96*data.plot[,seq.p]#
          coverage.ind <- (LB.beta <= beta.true[,i]) * (UB.beta >= beta.true[,i])  # = 1 when both true, or beta is in CI#
          coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop ] <- apply(coverage.ind, 2, mean, na.rm=T)*100#
        }#
        se.emp.N.X[n.loop,x.loop,(p.tot+1):(3*p.tot)] = rep(se.emp.N.X[n.loop,x.loop,1:p.tot],2)#
      } # end of X loops#
      mean.SE[n.loop,] <- apply(mean.SE.N.X[n.loop,,],2,mean, na.rm=T)     # expectation over X#
      se.SE[n.loop,] <- sqrt(apply(var.SE.N.X[n.loop,,],2,mean, na.rm=T) + apply(mean.SE.N.X[n.loop,,],2,var, na.rm=T))  # standard error unconditional on X#
      se.true[n.loop,] <- se.SE[n.loop,1:p.tot]#
      # Make box data for 95% confidence intervals#
      se.box[n.loop,,] <- outer(c(2,2,0,-2,-2), se.SE[n.loop,p.tot+1:(3*p.tot)]) + outer(rep(1,5), mean.SE[n.loop,p.tot+1:(3*p.tot)])#
    }   # end of N loop#
    bias.SE.N.X <- mean.SE.N.X[,,(p.tot+1):(4*p.tot)] - se.emp.N.X#
    se.SE.N.X <- sqrt(var.SE.N.X[,,(p.tot+1):(4*p.tot)])#
    bias.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    se.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
    out.post <- paste(out.post,file.post,sep='')#
#     out.post <- paste(out.post,'b_mle_3',sep='')#
  }     # end of f loop#
}       # end of m loop#
###note that rand 87 n=320 is empty (there's a dummy file in the post-processed folder), so we need to delete that entry from the output before we save it#
coverage.prob[5,87,,4]<-rep(NA,length(coverage.prob[5,87,,4]))#
#
save.image("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
#
end.time = proc.time()#
print(end.time - start.time)
#july 1 2016#
  #this file takes in the necessary csv files with summary stats for each boxplot and actually #
  #creates the files that go into the paper#
  #note that we no longer need to do preprocessing bc the key stats are saved in the csv files in this directory#
load("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
   # Boxplots/95% CI plots#
    # Boxplots of variances#
    legend.loc <- rep("topright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
    col.vec <- c('#2c7bb6', '#d7191c', '#fdae61')#
      #fdae61#
      #ffffbf#
      #abd9e9#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e <- .25                               # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
 out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
out.post <- paste(out.post,file.post,sep='')#
n.names <- N.test  #c('n = 10',N.test[2:length(N.test)])#
#
# col.vec <- c('#8da0cb', '#fc8d62', '#66c2a5')#
col.vec <- c('#d7191c', '#8da0cb', '#fdae61')#
#
legend.loc <- rep("bottomright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
nn  <- 5   # number of data series#
# Boxplots#
#if (model=='rand'){#
  for (i in 1:p.tot){#
    y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    name <- paste('CP2_se_',i,sep='')#
    name.file <- paste(out.post, name, sep="_")#
    plot.wd <- 4    # + .3*(i==1) #
    pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    if(i==1){#
      y.name.2 <- 'Non-Exchangeable Errors'#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    } else {#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    }#
    blw <- 2   # box line width#
    seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    y.range <- range(coverage.prob[,,seq.plots[1:3],m.loop], na.rm=T)#
    y.range[2] <- 1.00#
    y.range[1] <- .23  #max(y.range[1],50)#
    coverage.prob.1 <- coverage.prob/100#
    #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    boxplot(t(coverage.prob.1[,,seq.plots[1],m.loop]), ylab="Coverage", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    boxplot(t(coverage.prob.1[,,seq.plots[2],m.loop]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    boxplot(t(coverage.prob.1[,,seq.plots[3],m.loop]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    if (i == 3) { #
      legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             col = c(col.vec, 'black'), #
             bty='n', horiz=F, cex = 1.)#
    }#
    #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    abline(h=.95,col='black',lty=2, lwd=1.5)#
    axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#     #
    dev.off()#
  }#
# #} else{   #
	# ######all the other plots#
# #  for (i in 1:p.tot){#
    # y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    # name <- paste('CP2_se_',i,sep='')#
    # name.file <- paste(out.post, name, sep="_")#
    # pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    # #plot.wd <- 4    #+ .3*(i==1) #
    # pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    # if(i==1){#
      # if (model=='iid'){#
        # y.name.2 <- 'IID Errors'#
      # } else {#
        # y.name.2 <- 'Exchangeable Errors'#
      # }#
	# par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    # } else {#
      # par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    # }#
    # blw <- 2   # box line width  blw <- 2   # box line width#
    # seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    # y.range <- range(coverage.prob[,,seq.plots[1:3]], na.rm=T)#
    # y.range[2] <- 1.00#
    # y.range[1] <- .23  #max(y.range[1],50)#
    # coverage.prob.1 <- coverage.prob/100#
    # #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    # boxplot(t(coverage.prob.1[,,seq.plots[1]]), ylab="Coverage", xlab="", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            # ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    # boxplot(t(coverage.prob.1[,,seq.plots[2]]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            # border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    # boxplot(t(coverage.prob.1[,,seq.plots[3]]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            # at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    # if (i == 3) { #
      # legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             # col = c(col.vec, 'black'), #
             # bty='n', horiz=F, cex = 1.0)#
    # }#
    # #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    # abline(h=.95,col='black',lty=2, lwd=1.5)#
       # axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    # title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#
# #     #
#
    # dev.off()#
  # }#
# ##}#
}
m.loop
dim(coverage.prog)
dim(coverage.prob)
coverage.prob[,,,4]
coverage.prob[,,,3]
Model.test
m.loop
dim(coverage.prob)
##
##this file prepares the output csv files necessary to plot the coverages#
#the make_figures file actually plots them and shoudl work as a stand-alone using what's in this #
#directory as inputs#
##
print("updated file")#
#
# INPUTS#
# File management #
data.in.name <- "Data_c_ols_4_corrected"        # name for data directory#
data.out.name <- "Plots_20_320"                 # name for plot directory#
file.post <- "_c_ols_4_SE"                      # post name for files to read in#
file.post.160 <- "_c_ols_SE"                    # postscript for files > 160 (naming was different at times)#
#setwd("~/Documents/work_R/Sandwich/paper_bv/Data_c_ols_4")     # set working directory, under which all files are assumed to be located#
#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e.test <- c(.25)                                # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
##not post processed#
#iid 160 1#
#
# Create directories#
dir.in <- '~/Dropbox/netreg_cluster/post_processed/'#file.path(getwd(),data.in.name)         # data input directory#
dir.out  <- '~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/figures' #file.path(getwd(),data.out.name)      # plot output directory#
#dir.create(file.path(getwd(),data.out.name))#
#
start.time <- proc.time()                         # start time#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
  for (f.loop in 1:length(f.e.test)) {#
    f.e <- f.e.test[f.loop]#
    # Build data#
    se.SE <- matrix(0, length(N.test), 4*p.tot)           # undconditional standard error of data #
    mean.SE  <- matrix(0, length(N.test), 4*p.tot)        # undconditional expectation error of data#
    se.true <- matrix(0, length(N.test), p.tot)           # estimates of true standard error#
    se.box <- array(0, c(length(N.test), 5, 3*p.tot))     # boxplot 5# summaries#
    var.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    mean.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    bias.SE.N.X <- array(0,c(length(N.test),X.test,3*p.tot))#
    se.emp.N.X <-  array(0,c(length(N.test),X.test,3*p.tot))     # S, U, HC empirical standard errors#
    coverage.prob <- array(0,c(length(N.test),X.test,3*p.tot,length(Model.test)))#
    for (n.loop in 1:length(N.test)) {#
      n.tot <- N.test[n.loop]     # number of members#
      d.tot <- n.tot*(n.tot-1)    # number of dyads in directed setting#
      for (x.loop in 1:X.test) {#
        if (n.tot<100){ #
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        } else {#
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post.160,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        #}}#
        }#
        # Read in data and eliminate extreme outliers#
        data.plot <- read.table(file= in.file, header=T)#
        if(remove.outlier == T) { #
          i.outlier <- which(abs(data.plot) > 1000, arr.ind=T)#
          data.plot[i.outlier[,1],] <- NA#
        }#
#
        var.SE.N.X[n.loop,x.loop,] <-apply(data.plot[,1:(4*p.tot)],2,var, na.rm=T)#
        mean.SE.N.X[n.loop,x.loop,] <- apply(data.plot[,1:(4*p.tot)],2,mean, na.rm=T)#
        beta.hat.in <- data.plot[,1:p.tot] #
        beta.true <- outer(rep(1,Rep.test),beta.1)#
        # Post process empirical variances and MSEs#
        for (i in 1:p.tot) {#
#           i.store = i.mat[i,1];   #
#           j.store = i.mat[i,2];#
          # empirical variance#
#           V.emp.N.X[n.loop,x.loop,i] = cov(beta.hat.in[i.store], beta.hat.in[j.store]);#
          se.emp.N.X[n.loop,x.loop,i] = sqrt(var(beta.hat.in[,i]) )#
          seq.p <- p.tot + rep(i,3) + c(0,1,2)*p.tot#
          UB.beta <- beta.hat.in[,i] + 1.96*data.plot[,seq.p]#
          LB.beta <- beta.hat.in[,i] - 1.96*data.plot[,seq.p]#
          coverage.ind <- (LB.beta <= beta.true[,i]) * (UB.beta >= beta.true[,i])  # = 1 when both true, or beta is in CI#
          if(m.loop==1){print(apply(coverage.ind, 2, mean, na.rm=T)*100)}#
          coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop] <- apply(coverage.ind, 2, mean, na.rm=T)*100#
        }#
        se.emp.N.X[n.loop,x.loop,(p.tot+1):(3*p.tot)] = rep(se.emp.N.X[n.loop,x.loop,1:p.tot],2)#
      } # end of X loops#
      mean.SE[n.loop,] <- apply(mean.SE.N.X[n.loop,,],2,mean, na.rm=T)     # expectation over X#
      se.SE[n.loop,] <- sqrt(apply(var.SE.N.X[n.loop,,],2,mean, na.rm=T) + apply(mean.SE.N.X[n.loop,,],2,var, na.rm=T))  # standard error unconditional on X#
      se.true[n.loop,] <- se.SE[n.loop,1:p.tot]#
      # Make box data for 95% confidence intervals#
      se.box[n.loop,,] <- outer(c(2,2,0,-2,-2), se.SE[n.loop,p.tot+1:(3*p.tot)]) + outer(rep(1,5), mean.SE[n.loop,p.tot+1:(3*p.tot)])#
    }   # end of N loop#
    bias.SE.N.X <- mean.SE.N.X[,,(p.tot+1):(4*p.tot)] - se.emp.N.X#
    se.SE.N.X <- sqrt(var.SE.N.X[,,(p.tot+1):(4*p.tot)])#
    bias.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    se.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
    out.post <- paste(out.post,file.post,sep='')#
#     out.post <- paste(out.post,'b_mle_3',sep='')#
  }     # end of f loop#
}       # end of m loop#
###note that rand 87 n=320 is empty (there's a dummy file in the post-processed folder), so we need to delete that entry from the output before we save it#
coverage.prob[5,87,,4]<-rep(NA,length(coverage.prob[5,87,,4]))#
#
save.image("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
#
end.time = proc.time()#
print(end.time - start.time)
##
##this file prepares the output csv files necessary to plot the coverages#
#the make_figures file actually plots them and shoudl work as a stand-alone using what's in this #
#directory as inputs#
##
print("updated file")#
#
# INPUTS#
# File management #
data.in.name <- "Data_c_ols_4_corrected"        # name for data directory#
data.out.name <- "Plots_20_320"                 # name for plot directory#
file.post <- "_c_ols_4_SE"                      # post name for files to read in#
file.post.160 <- "_c_ols_SE"                    # postscript for files > 160 (naming was different at times)#
#setwd("~/Documents/work_R/Sandwich/paper_bv/Data_c_ols_4")     # set working directory, under which all files are assumed to be located#
#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e.test <- c(.25)                                # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
##not post processed#
#iid 160 1#
#
# Create directories#
dir.in <- '~/Dropbox/netreg_cluster/post_processed/'#file.path(getwd(),data.in.name)         # data input directory#
dir.out  <- '~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/figures' #file.path(getwd(),data.out.name)      # plot output directory#
#dir.create(file.path(getwd(),data.out.name))#
#
start.time <- proc.time()                         # start time#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
  for (f.loop in 1:length(f.e.test)) {#
    f.e <- f.e.test[f.loop]#
    # Build data#
    se.SE <- matrix(0, length(N.test), 4*p.tot)           # undconditional standard error of data #
    mean.SE  <- matrix(0, length(N.test), 4*p.tot)        # undconditional expectation error of data#
    se.true <- matrix(0, length(N.test), p.tot)           # estimates of true standard error#
    se.box <- array(0, c(length(N.test), 5, 3*p.tot))     # boxplot 5# summaries#
    var.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    mean.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    bias.SE.N.X <- array(0,c(length(N.test),X.test,3*p.tot))#
    se.emp.N.X <-  array(0,c(length(N.test),X.test,3*p.tot))     # S, U, HC empirical standard errors#
    coverage.prob <- array(0,c(length(N.test),X.test,3*p.tot,length(Model.test)))#
    for (n.loop in 1:length(N.test)) {#
      n.tot <- N.test[n.loop]     # number of members#
      d.tot <- n.tot*(n.tot-1)    # number of dyads in directed setting#
      for (x.loop in 1:X.test) {#
        if (n.tot<100){ #
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        } else {#
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post.160,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        #}}#
        }#
        # Read in data and eliminate extreme outliers#
        data.plot <- read.table(file= in.file, header=T)#
        if(remove.outlier == T) { #
          i.outlier <- which(abs(data.plot) > 1000, arr.ind=T)#
          data.plot[i.outlier[,1],] <- NA#
        }#
#
        var.SE.N.X[n.loop,x.loop,] <-apply(data.plot[,1:(4*p.tot)],2,var, na.rm=T)#
        mean.SE.N.X[n.loop,x.loop,] <- apply(data.plot[,1:(4*p.tot)],2,mean, na.rm=T)#
        beta.hat.in <- data.plot[,1:p.tot] #
        beta.true <- outer(rep(1,Rep.test),beta.1)#
        # Post process empirical variances and MSEs#
        for (i in 1:p.tot) {#
#           i.store = i.mat[i,1];   #
#           j.store = i.mat[i,2];#
          # empirical variance#
#           V.emp.N.X[n.loop,x.loop,i] = cov(beta.hat.in[i.store], beta.hat.in[j.store]);#
          se.emp.N.X[n.loop,x.loop,i] = sqrt(var(beta.hat.in[,i]) )#
          seq.p <- p.tot + rep(i,3) + c(0,1,2)*p.tot#
          UB.beta <- beta.hat.in[,i] + 1.96*data.plot[,seq.p]#
          LB.beta <- beta.hat.in[,i] - 1.96*data.plot[,seq.p]#
          coverage.ind <- (LB.beta <= beta.true[,i]) * (UB.beta >= beta.true[,i])  # = 1 when both true, or beta is in CI#
          coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop] <- apply(coverage.ind, 2, mean, na.rm=T)*100#
			if(m.loop==1){print( coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop])}#
        }#
        se.emp.N.X[n.loop,x.loop,(p.tot+1):(3*p.tot)] = rep(se.emp.N.X[n.loop,x.loop,1:p.tot],2)#
      } # end of X loops#
      mean.SE[n.loop,] <- apply(mean.SE.N.X[n.loop,,],2,mean, na.rm=T)     # expectation over X#
      se.SE[n.loop,] <- sqrt(apply(var.SE.N.X[n.loop,,],2,mean, na.rm=T) + apply(mean.SE.N.X[n.loop,,],2,var, na.rm=T))  # standard error unconditional on X#
      se.true[n.loop,] <- se.SE[n.loop,1:p.tot]#
      # Make box data for 95% confidence intervals#
      se.box[n.loop,,] <- outer(c(2,2,0,-2,-2), se.SE[n.loop,p.tot+1:(3*p.tot)]) + outer(rep(1,5), mean.SE[n.loop,p.tot+1:(3*p.tot)])#
    }   # end of N loop#
    bias.SE.N.X <- mean.SE.N.X[,,(p.tot+1):(4*p.tot)] - se.emp.N.X#
    se.SE.N.X <- sqrt(var.SE.N.X[,,(p.tot+1):(4*p.tot)])#
    bias.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    se.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
    out.post <- paste(out.post,file.post,sep='')#
#     out.post <- paste(out.post,'b_mle_3',sep='')#
  }     # end of f loop#
}       # end of m loop#
###note that rand 87 n=320 is empty (there's a dummy file in the post-processed folder), so we need to delete that entry from the output before we save it#
coverage.prob[5,87,,4]<-rep(NA,length(coverage.prob[5,87,,4]))#
#
save.image("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
#
end.time = proc.time()#
print(end.time - start.time)
coverage.prob[,,,1]
##
##this file prepares the output csv files necessary to plot the coverages#
#the make_figures file actually plots them and shoudl work as a stand-alone using what's in this #
#directory as inputs#
##
print("updated file")#
#
# INPUTS#
# File management #
data.in.name <- "Data_c_ols_4_corrected"        # name for data directory#
data.out.name <- "Plots_20_320"                 # name for plot directory#
file.post <- "_c_ols_4_SE"                      # post name for files to read in#
file.post.160 <- "_c_ols_SE"                    # postscript for files > 160 (naming was different at times)#
#setwd("~/Documents/work_R/Sandwich/paper_bv/Data_c_ols_4")     # set working directory, under which all files are assumed to be located#
#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e.test <- c(.25)                                # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
##not post processed#
#iid 160 1#
#
# Create directories#
dir.in <- '~/Dropbox/netreg_cluster/post_processed/'#file.path(getwd(),data.in.name)         # data input directory#
dir.out  <- '~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/figures' #file.path(getwd(),data.out.name)      # plot output directory#
#dir.create(file.path(getwd(),data.out.name))#
#
start.time <- proc.time()                         # start time#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
  for (f.loop in 1:length(f.e.test)) {#
    f.e <- f.e.test[f.loop]#
    # Build data#
    se.SE <- matrix(0, length(N.test), 4*p.tot)           # undconditional standard error of data #
    mean.SE  <- matrix(0, length(N.test), 4*p.tot)        # undconditional expectation error of data#
    se.true <- matrix(0, length(N.test), p.tot)           # estimates of true standard error#
    se.box <- array(0, c(length(N.test), 5, 3*p.tot))     # boxplot 5# summaries#
    var.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    mean.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    bias.SE.N.X <- array(0,c(length(N.test),X.test,3*p.tot))#
    se.emp.N.X <-  array(0,c(length(N.test),X.test,3*p.tot))     # S, U, HC empirical standard errors#
    coverage.prob <- array(0,c(length(N.test),X.test,3*p.tot,length(Model.test)))#
    for (n.loop in 1:length(N.test)) {#
      n.tot <- N.test[n.loop]     # number of members#
      d.tot <- n.tot*(n.tot-1)    # number of dyads in directed setting#
      for (x.loop in 1:X.test) {#
        if (n.tot<100){ #
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        } else {#
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post.160,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        #}}#
        }#
        # Read in data and eliminate extreme outliers#
        data.plot <- read.table(file= in.file, header=T)#
        if(remove.outlier == T) { #
          i.outlier <- which(abs(data.plot) > 1000, arr.ind=T)#
          data.plot[i.outlier[,1],] <- NA#
        }#
#
        var.SE.N.X[n.loop,x.loop,] <-apply(data.plot[,1:(4*p.tot)],2,var, na.rm=T)#
        mean.SE.N.X[n.loop,x.loop,] <- apply(data.plot[,1:(4*p.tot)],2,mean, na.rm=T)#
        beta.hat.in <- data.plot[,1:p.tot] #
        beta.true <- outer(rep(1,Rep.test),beta.1)#
        # Post process empirical variances and MSEs#
        for (i in 1:p.tot) {#
#           i.store = i.mat[i,1];   #
#           j.store = i.mat[i,2];#
          # empirical variance#
#           V.emp.N.X[n.loop,x.loop,i] = cov(beta.hat.in[i.store], beta.hat.in[j.store]);#
          se.emp.N.X[n.loop,x.loop,i] = sqrt(var(beta.hat.in[,i]) )#
          seq.p <- p.tot + rep(i,3) + c(0,1,2)*p.tot#
          UB.beta <- beta.hat.in[,i] + 1.96*data.plot[,seq.p]#
          LB.beta <- beta.hat.in[,i] - 1.96*data.plot[,seq.p]#
          coverage.ind <- (LB.beta <= beta.true[,i]) * (UB.beta >= beta.true[,i])  # = 1 when both true, or beta is in CI#
          coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop] <- apply(coverage.ind, 2, mean, na.rm=T)*100#
		#if(m.loop==1){print( coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop])}#
        }#
        se.emp.N.X[n.loop,x.loop,(p.tot+1):(3*p.tot)] = rep(se.emp.N.X[n.loop,x.loop,1:p.tot],2)#
      } # end of X loops#
      mean.SE[n.loop,] <- apply(mean.SE.N.X[n.loop,,],2,mean, na.rm=T)     # expectation over X#
      se.SE[n.loop,] <- sqrt(apply(var.SE.N.X[n.loop,,],2,mean, na.rm=T) + apply(mean.SE.N.X[n.loop,,],2,var, na.rm=T))  # standard error unconditional on X#
      se.true[n.loop,] <- se.SE[n.loop,1:p.tot]#
      # Make box data for 95% confidence intervals#
      se.box[n.loop,,] <- outer(c(2,2,0,-2,-2), se.SE[n.loop,p.tot+1:(3*p.tot)]) + outer(rep(1,5), mean.SE[n.loop,p.tot+1:(3*p.tot)])#
    }   # end of N loop#
    bias.SE.N.X <- mean.SE.N.X[,,(p.tot+1):(4*p.tot)] - se.emp.N.X#
    se.SE.N.X <- sqrt(var.SE.N.X[,,(p.tot+1):(4*p.tot)])#
    bias.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    se.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
    out.post <- paste(out.post,file.post,sep='')#
#     out.post <- paste(out.post,'b_mle_3',sep='')#
  }     # end of f loop#
}       # end of m loop#
###note that rand 87 n=320 is empty (there's a dummy file in the post-processed folder), so we need to delete that entry from the output before we save it#
#coverage.prob[5,87,,4]<-rep(NA,length(coverage.prob[5,87,,4]))#
#
save.image("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
#
end.time = proc.time()#
print(end.time - start.time)
coverage.prob[,,,1]
m.loop
##
##this file prepares the output csv files necessary to plot the coverages#
#the make_figures file actually plots them and shoudl work as a stand-alone using what's in this #
#directory as inputs#
##
print("updated file")#
#
# INPUTS#
# File management #
data.in.name <- "Data_c_ols_4_corrected"        # name for data directory#
data.out.name <- "Plots_20_320"                 # name for plot directory#
file.post <- "_c_ols_4_SE"                      # post name for files to read in#
file.post.160 <- "_c_ols_SE"                    # postscript for files > 160 (naming was different at times)#
#setwd("~/Documents/work_R/Sandwich/paper_bv/Data_c_ols_4")     # set working directory, under which all files are assumed to be located#
#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e.test <- c(.25)                                # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
##not post processed#
#iid 160 1#
#
# Create directories#
dir.in <- '~/Dropbox/netreg_cluster/post_processed/'#file.path(getwd(),data.in.name)         # data input directory#
dir.out  <- '~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/figures' #file.path(getwd(),data.out.name)      # plot output directory#
#dir.create(file.path(getwd(),data.out.name))#
#
start.time <- proc.time()                         # start time#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
    coverage.prob <- array(0,c(length(N.test),X.test,3*p.tot,length(Model.test)))#
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
  for (f.loop in 1:length(f.e.test)) {#
    f.e <- f.e.test[f.loop]#
    # Build data#
    se.SE <- matrix(0, length(N.test), 4*p.tot)           # undconditional standard error of data #
    mean.SE  <- matrix(0, length(N.test), 4*p.tot)        # undconditional expectation error of data#
    se.true <- matrix(0, length(N.test), p.tot)           # estimates of true standard error#
    se.box <- array(0, c(length(N.test), 5, 3*p.tot))     # boxplot 5# summaries#
    var.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    mean.SE.N.X <- array(0,c(length(N.test),X.test,4*p.tot))#
    bias.SE.N.X <- array(0,c(length(N.test),X.test,3*p.tot))#
    se.emp.N.X <-  array(0,c(length(N.test),X.test,3*p.tot))     # S, U, HC empirical standard errors#
    for (n.loop in 1:length(N.test)) {#
      n.tot <- N.test[n.loop]     # number of members#
      d.tot <- n.tot*(n.tot-1)    # number of dyads in directed setting#
      for (x.loop in 1:X.test) {#
        if (n.tot<100){ #
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        } else {#
          in.name <- paste(model, paste('fe',f.e*100,sep=""), paste('n',n.tot,sep=""), paste('x',x.loop,sep=''), sep="_"  )#
          in.name <- paste(in.name,file.post.160,sep='')#
          in.file <- file.path(dir.in, paste(in.name,'txt',sep='.'))#
        #}}#
        }#
        # Read in data and eliminate extreme outliers#
        data.plot <- read.table(file= in.file, header=T)#
        if(remove.outlier == T) { #
          i.outlier <- which(abs(data.plot) > 1000, arr.ind=T)#
          data.plot[i.outlier[,1],] <- NA#
        }#
#
        var.SE.N.X[n.loop,x.loop,] <-apply(data.plot[,1:(4*p.tot)],2,var, na.rm=T)#
        mean.SE.N.X[n.loop,x.loop,] <- apply(data.plot[,1:(4*p.tot)],2,mean, na.rm=T)#
        beta.hat.in <- data.plot[,1:p.tot] #
        beta.true <- outer(rep(1,Rep.test),beta.1)#
        # Post process empirical variances and MSEs#
        for (i in 1:p.tot) {#
#           i.store = i.mat[i,1];   #
#           j.store = i.mat[i,2];#
          # empirical variance#
#           V.emp.N.X[n.loop,x.loop,i] = cov(beta.hat.in[i.store], beta.hat.in[j.store]);#
          se.emp.N.X[n.loop,x.loop,i] = sqrt(var(beta.hat.in[,i]) )#
          seq.p <- p.tot + rep(i,3) + c(0,1,2)*p.tot#
          UB.beta <- beta.hat.in[,i] + 1.96*data.plot[,seq.p]#
          LB.beta <- beta.hat.in[,i] - 1.96*data.plot[,seq.p]#
          coverage.ind <- (LB.beta <= beta.true[,i]) * (UB.beta >= beta.true[,i])  # = 1 when both true, or beta is in CI#
          coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop] <- apply(coverage.ind, 2, mean, na.rm=T)*100#
		#if(m.loop==1){print( coverage.prob[n.loop,x.loop, (seq.p-p.tot),m.loop])}#
        }#
        se.emp.N.X[n.loop,x.loop,(p.tot+1):(3*p.tot)] = rep(se.emp.N.X[n.loop,x.loop,1:p.tot],2)#
      } # end of X loops#
      mean.SE[n.loop,] <- apply(mean.SE.N.X[n.loop,,],2,mean, na.rm=T)     # expectation over X#
      se.SE[n.loop,] <- sqrt(apply(var.SE.N.X[n.loop,,],2,mean, na.rm=T) + apply(mean.SE.N.X[n.loop,,],2,var, na.rm=T))  # standard error unconditional on X#
      se.true[n.loop,] <- se.SE[n.loop,1:p.tot]#
      # Make box data for 95% confidence intervals#
      se.box[n.loop,,] <- outer(c(2,2,0,-2,-2), se.SE[n.loop,p.tot+1:(3*p.tot)]) + outer(rep(1,5), mean.SE[n.loop,p.tot+1:(3*p.tot)])#
    }   # end of N loop#
    bias.SE.N.X <- mean.SE.N.X[,,(p.tot+1):(4*p.tot)] - se.emp.N.X#
    se.SE.N.X <- sqrt(var.SE.N.X[,,(p.tot+1):(4*p.tot)])#
    bias.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    se.80.box <- array(0,c(length(N.test),5,3*p.tot))#
    out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
    out.post <- paste(out.post,file.post,sep='')#
#     out.post <- paste(out.post,'b_mle_3',sep='')#
  }     # end of f loop#
}       # end of m loop#
###note that rand 87 n=320 is empty (there's a dummy file in the post-processed folder), so we need to delete that entry from the output before we save it#
coverage.prob[5,87,,4]<-rep(NA,length(coverage.prob[5,87,,4]))#
#
save.image("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
#
end.time = proc.time()#
print(end.time - start.time)
#july 1 2016#
  #this file takes in the necessary csv files with summary stats for each boxplot and actually #
  #creates the files that go into the paper#
  #note that we no longer need to do preprocessing bc the key stats are saved in the csv files in this directory#
load("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
   # Boxplots/95% CI plots#
    # Boxplots of variances#
    legend.loc <- rep("topright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
    col.vec <- c('#2c7bb6', '#d7191c', '#fdae61')#
      #fdae61#
      #ffffbf#
      #abd9e9#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e <- .25                               # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
 out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
out.post <- paste(out.post,file.post,sep='')#
n.names <- N.test  #c('n = 10',N.test[2:length(N.test)])#
#
# col.vec <- c('#8da0cb', '#fc8d62', '#66c2a5')#
col.vec <- c('#d7191c', '#8da0cb', '#fdae61')#
#
legend.loc <- rep("bottomright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
nn  <- 5   # number of data series#
# Boxplots#
#if (model=='rand'){#
  for (i in 1:p.tot){#
    y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    name <- paste('CP2_se_',i,sep='')#
    name.file <- paste(out.post, name, sep="_")#
    plot.wd <- 4    # + .3*(i==1) #
    pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    if(i==1){#
      y.name.2 <- 'Non-Exchangeable Errors'#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    } else {#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    }#
    blw <- 2   # box line width#
    seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    y.range <- range(coverage.prob[,,seq.plots[1:3],m.loop], na.rm=T)#
    y.range[2] <- 1.00#
    y.range[1] <- .23  #max(y.range[1],50)#
    coverage.prob.1 <- coverage.prob/100#
    #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    boxplot(t(coverage.prob.1[,,seq.plots[1],m.loop]), ylab="Coverage", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    boxplot(t(coverage.prob.1[,,seq.plots[2],m.loop]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    boxplot(t(coverage.prob.1[,,seq.plots[3],m.loop]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    if (i == 3) { #
      legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             col = c(col.vec, 'black'), #
             bty='n', horiz=F, cex = 1.)#
    }#
    #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    abline(h=.95,col='black',lty=2, lwd=1.5)#
    axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#     #
    dev.off()#
  }#
# #} else{   #
	# ######all the other plots#
# #  for (i in 1:p.tot){#
    # y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    # name <- paste('CP2_se_',i,sep='')#
    # name.file <- paste(out.post, name, sep="_")#
    # pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    # #plot.wd <- 4    #+ .3*(i==1) #
    # pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    # if(i==1){#
      # if (model=='iid'){#
        # y.name.2 <- 'IID Errors'#
      # } else {#
        # y.name.2 <- 'Exchangeable Errors'#
      # }#
	# par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    # } else {#
      # par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    # }#
    # blw <- 2   # box line width  blw <- 2   # box line width#
    # seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    # y.range <- range(coverage.prob[,,seq.plots[1:3]], na.rm=T)#
    # y.range[2] <- 1.00#
    # y.range[1] <- .23  #max(y.range[1],50)#
    # coverage.prob.1 <- coverage.prob/100#
    # #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    # boxplot(t(coverage.prob.1[,,seq.plots[1]]), ylab="Coverage", xlab="", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            # ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    # boxplot(t(coverage.prob.1[,,seq.plots[2]]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            # border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    # boxplot(t(coverage.prob.1[,,seq.plots[3]]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            # at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    # if (i == 3) { #
      # legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             # col = c(col.vec, 'black'), #
             # bty='n', horiz=F, cex = 1.0)#
    # }#
    # #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    # abline(h=.95,col='black',lty=2, lwd=1.5)#
       # axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    # title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#
# #     #
#
    # dev.off()#
  # }#
# ##}#
}
#july 1 2016#
  #this file takes in the necessary csv files with summary stats for each boxplot and actually #
  #creates the files that go into the paper#
  #note that we no longer need to do preprocessing bc the key stats are saved in the csv files in this directory#
load("~/Dropbox/git_to_work/network_ci/simulations/paper_bv/generate_plots_paper/processedfiles.RData")#
   # Boxplots/95% CI plots#
    # Boxplots of variances#
    legend.loc <- rep("topright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
    col.vec <- c('#2c7bb6', '#d7191c', '#fdae61')#
      #fdae61#
      #ffffbf#
      #abd9e9#
# Model variables (INPUTS)#
Model.test <- c('iid', 'sr', 'ble', 'rand')       # iid, sr, ble, rand, data generation type#
f.e <- .25                               # proportion of total variance of iid/measurement error#
N.test <- c(20,40,80,160,320)                     # network size to be plotted#
X.test <- 100;                                    # Number of X to plot#
#
# Simulation parameters (don't change)#
p.tot <- 4                                       # Number of coefficients#
Rep.test <- 1000                                 # Number of reps performed#
out.length <- 4*p.tot*(p.tot+1)/2 + p.tot + 2    # 4 estimators* number of unique variances + beta + MSE_0#
remove.outlier <- F                              # remove crazy outlying betas? (only use for binary data)#
beta.1 <- rep(1,p.tot)                           # true beta to which estimators are compared #
# Matrix of diagonal unfolding#
row.i  <- NULL#
col.i <- NULL#
for (i in 1:p.tot) {#
  row.i <- c(row.i, 1:(p.tot-i+1))#
  col.i <- c(col.i, i:p.tot)#
}#
i.mat <- matrix(0,p.tot*(p.tot+1)/2,2)#
i.mat[,1] <- row.i#
i.mat[,2] <- col.i#
#
A.i <- matrix(1:p.tot^2,p.tot,p.tot)#
i.unfold <- A.i[i.mat]#
########################
## Aronow-type plots ###
########################
for (m.loop in 1:length(Model.test)) {#
  model <- Model.test[m.loop]   #
 out.post <- paste(model, paste('fe',100*f.e,sep=""), sep="_"  )#
out.post <- paste(out.post,file.post,sep='')#
n.names <- N.test  #c('n = 10',N.test[2:length(N.test)])#
#
# col.vec <- c('#8da0cb', '#fc8d62', '#66c2a5')#
col.vec <- c('#d7191c', '#8da0cb', '#fdae61')#
#
legend.loc <- rep("bottomright",6);  #legend.loc[c(1:3,6)]  <- 'bottomright'#
nn  <- 5   # number of data series#
# Boxplots#
#if (model=='rand'){#
  for (i in 1:p.tot){#
    y.name <- ''  # substitute('Coverage Probability for'~beta[sub], list(sub = i) )#
    name <- paste('CP2_se_',i,sep='')#
    name.file <- paste(out.post, name, sep="_")#
    plot.wd <- 4    # + .3*(i==1) #
    pdf( file=file.path(dir.out, paste(name.file,'pdf',sep='.')), width = plot.wd, height = 4.4)#
    if(i==1){#
      y.name.2 <- 'Non-Exchangeable Errors'#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    } else {#
      par(mar = c(3, 3, .2, .2), mgp=c(1.8,.5,0), cex.lab=1.3, cex.axis=1.2) #
    }#
    blw <- 2   # box line width#
    seq.plots <- seq(i,i+2*p.tot,p.tot)     #21+i,6)#
    y.range <- range(coverage.prob[,,seq.plots[1:3],m.loop], na.rm=T)#
    y.range[2] <- 1.00#
    y.range[1] <- .23  #max(y.range[1],50)#
    coverage.prob.1 <- coverage.prob/100#
    #       y.range <- c(0,1)*(i==1) + c(0,.6)*(i==2)#
    boxplot(t(coverage.prob.1[,,seq.plots[1],m.loop]), ylab="Coverage", names=N.test, border=col.vec[1], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,  #
            ylim=y.range, at=(nn*(1:length(N.test))-(nn - 1)), xlim=c(0,(nn*length(N.test))-1), xaxt='n', pch=1 )#
    boxplot(t(coverage.prob.1[,,seq.plots[2],m.loop]), names=N.test, add=T, boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            border=col.vec[2], at=(nn*(1:length(N.test))-(nn - 2)), xaxt="n", pch=2)#
    boxplot(t(coverage.prob.1[,,seq.plots[3],m.loop]), add=T, border=col.vec[3], boxlwd=blw, whisklty=1, whisklwd=blw, staplelty=1, staplelwd=blw, outlwd=blw,#
            at=(nn*(1:length(N.test))- (nn - 3) ),xaxt="n", pch=3)#
    if (i == 4) { #
      legend('bottomleft', c("Exchangeable","Dyadic Clustering", "Heteroskedasticity-Consistent", 'True 95%'), lty=c(1,1,1,2), lwd=3*c(1,1,1,1),#
             col = c(col.vec, 'black'), #
             bty='n', horiz=F, cex = 1.)#
    }#
    #       points( (nn*(1:length(N.test))-floor(nn/2)), se.true[,i], col='black', pch=18, cex=2)#
    abline(h=.95,col='black',lty=2, lwd=1.5)#
    axis(side = 1, tck = -.015, labels = N.test,  at=(nn*(1:length(N.test))-floor(nn/2) - 1) )  #
    title(xlab='Number of nodes', font=3, mgp=c(1.9,.5,0), cex.lab=1.4 )#
#     #
    dev.off()#
  }#
  }
# ################################################################################
# # Multi-resolution blockmodel#
# ##
# # file: indian_village_figures.R#
# # #
# # This file makes the plots for the paper.  Assuming that we have already run India_village_estimation.R#
# ## and have results and have post-processed them with India_village_postprocess.R.  #
# ##
# ##
# # Author: tedwestling#
# ################################################################################
 rm(list = ls())#
#set your working directory to the top level multiresolution_networks folder#
setwd("~/Dropbox/git_to_work/multiresolution_networks")#
source("header.R")#
#load("data/results/village_59_mcmc_strongass_v1_postprocessed.Rdata")#
load("/Users/tylermccormick/Dropbox/git_to_work/village_59_mcmc_strongass_v1_postprocessed.Rdata")#
#
#assuming here that we've done no burn-in on the sampling, so removing first 1k iterations#
nburn=c(1:(length(chain1$mu[,1])*.25))#
#
#all the samples combined together for analysis later#
mcmc_samples <- list(beta=rbind(mcmc_samplesc1$beta[-nburn,], mcmc_samplesc2$beta[-nburn,],mcmc_samplesc3$beta[-nburn,], mcmc_samplesc4$beta[-nburn,]),#
                sigma=rbind(mcmc_samplesc1$sigma[-nburn,], mcmc_samplesc2$sigma[-nburn,], mcmc_samplesc3$sigma[-nburn,], mcmc_samplesc4$sigma[-nburn,]),#
                 pi=rbind(mcmc_samplesc1$pi[-nburn,], mcmc_samplesc2$pi[-nburn,], mcmc_samplesc3$pi[-nburn,], mcmc_samplesc4$pi[-nburn,]),#
                 mu=rbind(mcmc_samplesc1$mu[-nburn,], mcmc_samplesc2$mu[-nburn,], mcmc_samplesc3$mu[-nburn,], mcmc_samplesc4$mu[-nburn,]),#
                 Sigma=abind(mcmc_samplesc1$Sigma[-nburn,,], mcmc_samplesc2$Sigma[-nburn,,], mcmc_samplesc3$Sigma[-nburn,,], mcmc_samplesc4$Sigma[-nburn,,], along=1),#
                 B=abind(mcmc_samplesc1$B[-nburn,,], mcmc_samplesc2$B[-nburn,,], mcmc_samplesc3$B[-nburn,,], mcmc_samplesc4$B[-nburn,,], along=1),#
                 Z=abind(mcmc_samplesc1$Z[-nburn,,], mcmc_samplesc2$Z[-nburn,,], mcmc_samplesc3$Z[-nburn,,], mcmc_samplesc4$Z[-nburn,,], along=1),#
                 gamma=rbind(mcmc_samplesc1$gamma[-nburn,], mcmc_samplesc2$gamma[-nburn,], mcmc_samplesc3$gamma[-nburn,], mcmc_samplesc4$gamma[-nburn,]))#
#
#now do some mcmc checks with the "monitor" function from stan#
#note that this assumes you have at least two chains#
#separate arrays for analyzing convergence#
#note the first argument takes the form iterations, chains, paramters#
require(rstan)#
#set this based on the number of chains you've run#
howmanychains=4#
beta_array=array(dim=c(dim(mcmc_samplesc1$beta)[1],howmanychains,dim(mcmc_samplesc1$beta)[2]))#
beta_array[,1,]<-mcmc_samplesc1$beta#
beta_array[,2,]<-mcmc_samplesc2$beta#
beta_array[,3,]<-mcmc_samplesc3$beta#
beta_array[,4,]<-mcmc_samplesc4$beta#
#
sigma_array=array(dim=c(dim(mcmc_samplesc1$sigma)[1],howmanychains,dim(mcmc_samplesc1$sigma)[2]))#
sigma_array[,1,]<-mcmc_samplesc1$sigma#
sigma_array[,2,]<-mcmc_samplesc2$sigma#
sigma_array[,3,]<-mcmc_samplesc3$sigma#
sigma_array[,4,]<-mcmc_samplesc4$sigma#
pi_array=array(dim=c(dim(mcmc_samplesc1$pi)[1],howmanychains,dim(mcmc_samplesc1$pi)[2]))#
pi_array[,1,]<-mcmc_samplesc1$pi#
pi_array[,2,]<-mcmc_samplesc2$pi#
pi_array[,3,]<-mcmc_samplesc3$pi#
pi_array[,4,]<-mcmc_samplesc4$pi#
#
mu_array=array(dim=c(dim(mcmc_samplesc1$mu)[1],howmanychains,dim(mcmc_samplesc1$mu)[2]))#
mu_array[,1,]<-mcmc_samplesc1$mu#
mu_array[,2,]<-mcmc_samplesc2$mu#
mu_array[,3,]<-mcmc_samplesc3$mu#
mu_array[,4,]<-mcmc_samplesc4$mu#
#
Sigma_array=array(dim=c(dim(mcmc_samplesc1$Sigma)[1],howmanychains,4))#
Sigma_array[,1,]<-matrix(mcmc_samplesc1$Sigma,dim(mcmc_samplesc1$Sigma)[1],4)#
Sigma_array[,2,]<-matrix(mcmc_samplesc2$Sigma,dim(mcmc_samplesc2$Sigma)[1],4)#
Sigma_array[,3,]<-matrix(mcmc_samplesc3$Sigma,dim(mcmc_samplesc3$Sigma)[1],4)#
Sigma_array[,4,]<-matrix(mcmc_samplesc4$Sigma,dim(mcmc_samplesc4$Sigma)[1],4)#
#note there are 30 for 6 blocks (6*6-6 on the diagonal)#
#need to change if you're using fewer blocks#
B_array=array(dim=c(dim(mcmc_samplesc1$B)[1],howmanychains,((Khat*Khat)-Khat)))#
B_array[,1,]<-matrix(mcmc_samplesc1$B[is.na(mcmc_samplesc1$B)==F],dim(mcmc_samplesc1$B)[1],((Khat*Khat)-Khat))#
B_array[,2,]<-matrix(mcmc_samplesc2$B[is.na(mcmc_samplesc1$B)==F],dim(mcmc_samplesc2$B)[1],((Khat*Khat)-Khat))#
B_array[,3,]<-matrix(mcmc_samplesc3$B[is.na(mcmc_samplesc1$B)==F],dim(mcmc_samplesc3$B)[1],((Khat*Khat)-Khat))#
B_array[,4,]<-matrix(mcmc_samplesc4$B[is.na(mcmc_samplesc1$B)==F],dim(mcmc_samplesc4$B)[1],((Khat*Khat)-Khat))#
#
gamma_array=array(dim=c(dim(mcmc_samplesc1$gamma)[1],howmanychains,dim(mcmc_samplesc1$gamma)[2]))#
gamma_array[,1,]<-mcmc_samplesc1$gamma#
gamma_array[,2,]<-mcmc_samplesc2$gamma#
gamma_array[,3,]<-mcmc_samplesc3$gamma#
gamma_array[,4,]<-mcmc_samplesc4$gamma#
#
#monitor(B_array)#
#monitor(Sigma_array)#
#monitor(mu_array)#
#monitor(pi_array)#
#monitor(sigma_array)#
#monitor(beta_array)#
#
prefix="plots/"#
###make trace plots#
#mu#
pdf(file=paste(prefix,"mutrace.pdf",sep=''),height=10,width=6)#
par(mfrow=c(2,1))#
matplot(mu_array[-c(1:max(nburn)),,1],type='l',main="Traceplot for mu1",xlab="iteration",ylab="mu1")#
matplot(mu_array[-c(1:max(nburn)),,2],type='l',main="Traceplot for mu2",xlab="iteration",ylab="mu2")#
dev.off()#
pdf(file=paste(prefix,"betatrace.pdf",sep=''),height=10,width=6)#
par(mfrow=c(3,2))#
matplot(beta_array[-c(1:max(nburn)),,1],type='l',main="Traceplot for beta1",xlab="iteration",ylab="beta1")#
matplot(beta_array[-c(1:max(nburn)),,2],type='l',main="Traceplot for beta2",xlab="iteration",ylab="beta2")#
matplot(beta_array[-c(1:max(nburn)),,3],type='l',main="Traceplot for beta3",xlab="iteration",ylab="beta3")#
matplot(beta_array[-c(1:max(nburn)),,4],type='l',main="Traceplot for beta4",xlab="iteration",ylab="beta4")#
matplot(beta_array[-c(1:max(nburn)),,5],type='l',main="Traceplot for beta5",xlab="iteration",ylab="beta5")#
if(Khat==6){matplot(beta_array[-c(1:max(nburn)),,6],type='l',main="Traceplot for beta6",xlab="iteration",ylab="beta6")}#
dev.off()#
#
pdf(file=paste(prefix,"sigmatrace.pdf",sep=''),height=10,width=6)#
par(mfrow=c(3,2))#
matplot(sigma_array[-c(1:max(nburn)),,1],type='l',main="Traceplot for sigma1",xlab="iteration",ylab="sigma1")#
matplot(sigma_array[-c(1:max(nburn)),,2],type='l',main="Traceplot for sigma2",xlab="iteration",ylab="sigma2")#
matplot(sigma_array[-c(1:max(nburn)),,3],type='l',main="Traceplot for sigma3",xlab="iteration",ylab="sigma3")#
matplot(sigma_array[-c(1:max(nburn)),,4],type='l',main="Traceplot for sigma4",xlab="iteration",ylab="sigma4")#
matplot(sigma_array[-c(1:max(nburn)),,5],type='l',main="Traceplot for sigma5",xlab="iteration",ylab="sigma5")#
if(Khat==6){matplot(sigma_array[-c(1:max(nburn)),,6],type='l',main="Traceplot for sigma6",xlab="iteration",ylab="sigma6")}#
dev.off()#
pdf(file=paste(prefix,"pitrace.pdf",sep=''),height=10,width=6)#
par(mfrow=c(3,2))#
matplot(pi_array[-c(1:max(nburn)),,1],type='l',main="Traceplot for pi1",xlab="iteration",ylab="pi1")#
matplot(pi_array[-c(1:max(nburn)),,2],type='l',main="Traceplot for pi2",xlab="iteration",ylab="pi2")#
matplot(pi_array[-c(1:max(nburn)),,3],type='l',main="Traceplot for pi3",xlab="iteration",ylab="pi3")#
matplot(pi_array[-c(1:max(nburn)),,4],type='l',main="Traceplot for pi4",xlab="iteration",ylab="pi4")#
matplot(pi_array[-c(1:max(nburn)),,5],type='l',main="Traceplot for pi5",xlab="iteration",ylab="pi5")#
if(Khat==6){matplot(pi_array[-c(1:max(nburn)),,6],type='l',main="Traceplot for pi6",xlab="iteration",ylab="pi6")}#
dev.off()#
pdf(file=paste(prefix,"Sigmatrace.pdf",sep=''),height=10,width=6)#
par(mfrow=c(2,2))#
matplot(Sigma_array[-c(1:max(nburn)),,1],type='l',main="Traceplot for Sigma1",xlab="iteration",ylab="Sigma1")#
matplot(Sigma_array[-c(1:max(nburn)),,2],type='l',main="Traceplot for Sigma2",xlab="iteration",ylab="Sigma2")#
matplot(Sigma_array[-c(1:max(nburn)),,3],type='l',main="Traceplot for Sigma3",xlab="iteration",ylab="Sigma3")#
matplot(Sigma_array[-c(1:max(nburn)),,4],type='l',main="Traceplot for Sigma4",xlab="iteration",ylab="Sigma4")#
dev.off()#
#
set.seed(47676728)#
# CODE FOR COMPUTING JOINT POSTERIOR MODE:#
gamma_vecs <- apply(mcmc_samples$gamma,1,paste0, collapse='.')#
gamma_tab <- table(gamma_vecs)#
head(sort(gamma_tab))#
# If the maximum of gamma_tab is 1 then no membership appeared more than once and the marginal mode should be used instead#
gamma_mode <- names(gamma_tab)[which.max(gamma_tab)]#
joint_mode <- as.numeric(strsplit(gamma_mode, ".", fixed=TRUE)[[1]])#
#
# CODE FOR COMPUTING MARGINAL POSTERIOR MODES:#
marg_mode <- as.numeric(apply(mcmc_samples$gamma, 2, function(memb) names(table(memb))[which.max(table(memb))]))#
#
# CHOOSE ONE FOR DISPLAYING POSITIONS#
gamma_mode <- marg_mode#
#
# Plot blocked adjacency matrix - Figure 1#
png(paste(prefix,'blocked_adjacency.png',sep=''), width=2, height=2, units='in', res=300)#
plot_blocked_matrix(network, gamma_mode, sort=FALSE)#
dev.off()#
#
# ## Make dataset of latent positions#
# nsamp <- nrow(mcmc_samples$beta)#
# Z <- ldply(1:N, function(memb) {#
  # all <- data.frame(mcmc_samples$Z[,memb,])#
  # names(all) <- paste0("Z", 1:2)#
  # all$node <- memb#
  # all$sample <- 1:nsamp#
  # all$block <- mcmc_samples$gamma[,memb]#
  # return(all)#
# })#
#
# all_mean_df <- NULL#
# all_edge_df <- NULL#
# for(k in 1:K) {#
  # nodes_in <- which(gamma_mode == k)#
  # edges <- which(network[nodes_in,nodes_in]==1, arr.ind=TRUE)#
  # samples_df <- subset(Z, block==k & !is.na(Z1) & node %in% nodes_in)#
  # mean_df <- ddply(samples_df, .(node), function(subdf) data.frame(Z1=mean(subdf$Z1), Z2=mean(subdf$Z2)))#
  # mean_df$Block <- k#
  # all_mean_df <- rbind(all_mean_df, mean_df)#
  # edge_df <- data.frame(x=mean_df$Z1[edges[,1]], xend=mean_df$Z1[edges[,2]], y=mean_df$Z2[edges[,1]], yend=mean_df$Z2[edges[,2]])#
  # if(nrow(edges) != 0) edge_df$Block <- k#
  # all_edge_df <- rbind(all_edge_df, edge_df)#
# }#
# #
# ggplot(all_mean_df) + geom_point(aes(Z1, Z2)) + geom_segment(data=all_edge_df, aes(x=x, xend=xend, y=y, yend=yend))+ theme_bw() + facet_wrap(~block, nrow=floor(sqrt(K)), scales='free') +coord_fixed(ratio=1)#
#
#hhold <- read.dta('data/indian_village_raw/2. Demographics and Outcomes/household_characteristics.dta')#
hhold<-read.dta("/Users/tylermccormick/Dropbox/git_to_work/slurm/data/indian_village_raw/2. Demographics and Outcomes/household_characteristics.dta")#
hhold <- subset(hhold, village==vilno)#
#
# ###set up for plot by religion#
# hhold$hohreligion <- as.character(hhold$hohreligion)#
# names(hhold)[3] <- "node"#
# all_mean_df2 <- merge(hhold, all_mean_df, all.y = TRUE )#
# all_mean_df2$hohreligion[is.na(all_mean_df2$hohreligion)] <- "Unknown"#
# all_mean_df2$leader[is.na(all_mean_df2$leader)] <- "Unknown"#
#
# # Plot of latent positions - Figure 3#
# (g <- ggplot(all_mean_df2) + #
  # geom_segment(data=all_edge_df, aes(x=x, xend=xend, y=y, yend=yend), color='grey') + #
  # geom_point(aes(Z1, Z2, color=as.factor(leader), shape=hohreligion)) + #
  # theme_bw() +#
  # facet_wrap(~Block, nrow=2, scales='free') +#
  # coord_fixed(ratio=1) + #
  # scale_shape_manual(name="HH Religion", breaks=c("HINDUISM", "ISLAM", "CHRISTIANITY", "Unknown"), values=c(1, 2, 3, 4), labels=c("Hindu", "Muslim", "Christian", "Unknown")) +#
  # scale_color_manual(name="HH Status", values=c("black", "red", "blue"), labels=c("Non-leader", "Leader", "Unknown")) +#
  # theme(axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.grid=element_blank(), strip.background=element_blank()))#
# ggsave(paste(prefix,'latent_positions_byrel.png',sep=''), g, width=4.5, height=2.5, units='in', scale=1.5)#
# ###set up for plot by caste#
# hhold$castesubcaste <- as.character(hhold$castesubcaste)#
# names(hhold)[3] <- "node"#
# #merge the covariate information with the block and latent positions#
# all_mean_df2 <- merge(hhold, all_mean_df, all.y = TRUE )#
# all_mean_df2$castesubcaste[is.na(all_mean_df2$castesubcaste)] <- "Unknown"#
# all_mean_df2$leader[is.na(all_mean_df2$leader)] <- "Unknown"#
#
# # Plot of latent positions - Figure 3#
# (g <- ggplot(all_mean_df2) + #
  # geom_segment(data=all_edge_df, aes(x=x, xend=xend, y=y, yend=yend), color='grey') + #
  # geom_point(aes(Z1, Z2, color=as.factor(castesubcaste), shape=castesubcaste)) + #
  # theme_bw() +#
  # facet_wrap(~Block, nrow=2, scales='free') +#
  # coord_fixed(ratio=1) + #
  # #scale_shape_manual(name="HH Caste", breaks=c("GENERAL", "MINORITY", "OBC", "SCHEDULE CASTE", "SCHEDULE TRIBE", "Unknown"), values=c(1, 2, 3, 4, 5,6), labels=c("General", "Minority", "OBC", "Schedule caste", "Schedule tribe", "Unknown")) +#
  # #scale_color_manual(name="HH Status", values=c("black", "red", "blue"), labels=c("Non-leader", "Leader", "Unknown")) +#
  # scale_color_manual(name="HH Caste", values=c(1:6), labels=c("General", "Minority", "OBC", "Schedule caste", "Schedule tribe", "Unknown")) +#
  # theme(axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.grid=element_blank(), strip.background=element_blank()))#
# ggsave(paste(prefix,'latent_positions_bycaste.png',sep=''), g, width=4.5, height=2.5, units='in', scale=1.5)#
#
######################################################shaded by probabilty#
nsamp <- nrow(mcmc_samples$beta)#
Z <- ldply(1:N, function(memb) {#
 tab <- table(mcmc_samples$gamma[,memb])/nsamp#
 this_blocks <- as.numeric(names(tab)[tab > .00017]) ### has appeared in a block at least twice .00017#
#print(this_blocks)#
ldply(this_blocks, function(block) {#
  df <- data.frame(mcmc_samples$Z[mcmc_samples$gamma[,memb] == block,memb,])#
  names(df) <- paste0("Z", 1:2)#
  df$block <- block#
  df$node <- memb#
  return(df)#
 })#
})#
#
all_mean_df <- NULL#
all_edge_df <- NULL#
for(k in 1:K) {#
 nodes_in <- unique(Z$node[Z$block == k])#
 edges <- which(network[nodes_in,nodes_in]==1, arr.ind=TRUE)#
 samples_df <- subset(Z, block==k & !is.na(Z1) & node %in% nodes_in)#
####in the next line ted's code had 10000, changed to nsamp.  NEED TO DOUBLE CHECK THIS!!#
 mean_df <- ddply(samples_df, .(node), function(subdf) data.frame(Z1=mean(subdf$Z1), Z2=mean(subdf$Z2), prob=nrow(subdf)/nsamp))#
 mean_df$Block <- k#
 all_mean_df <- rbind(all_mean_df, mean_df)#
 edge_df <- data.frame(x=mean_df$Z1[edges[,1]], xend=mean_df$Z1[edges[,2]], y=mean_df$Z2[edges[,1]], yend=mean_df$Z2[edges[,2]], prob=(mean_df$prob[edges[,1]]+mean_df$prob[edges[,2]])/2,send=edges[,1],rec=edges[,2])#
 if(nrow(edges) != 0) edge_df$Block <- k#
 all_edge_df <- rbind(all_edge_df, edge_df)#
}#
#
###set up for plot by caste#
hhold$castesubcaste <- as.character(hhold$castesubcaste)#
names(hhold)[3] <- "node"#
#merge the covariate information with the block and latent positions#
all_mean_df2 <- merge(hhold, all_mean_df, all.y = TRUE )#
all_mean_df2$castesubcaste[is.na(all_mean_df2$castesubcaste)] <- "Unknown"#
all_mean_df2$leader[is.na(all_mean_df2$leader)] <- "Unknown"#
#
###truncate to only plot nodes with >40pct post prob of being in block#
all_mean_df2_tr=all_mean_df2[all_mean_df2$prob>0.4,]#
all_edge_df_tr <- NULL#
for(k in 1:K) {#
 nodes_in <- unique(all_mean_df2_tr$node[all_mean_df2_tr$Block == k])#
 edges <- which(network[nodes_in,nodes_in]==1, arr.ind=TRUE)#
 samples_df <- subset(Z, block==k & !is.na(Z1) & node %in% nodes_in)#
#edge_df_tr <- data.frame(x=all_mean_df2_tr$Z1[edges[,1]], xend=all_mean_df2_tr$Z1[edges[,2]], y=all_mean_df2_tr$Z2[edges[,1]], yend=all_mean_df2_tr$Z2[edges[,2]], prob=(all_mean_df2_tr$prob[edges[,1]]+all_mean_df2_tr$prob[edges[,2]])/2)#
	mean_df <- ddply(samples_df, .(node), function(subdf) data.frame(Z1=mean(subdf$Z1), Z2=mean(subdf$Z2), prob=nrow(subdf)/nsamp))#
 edge_df_tr <- data.frame(x=mean_df$Z1[edges[,1]], xend=mean_df$Z1[edges[,2]], y=mean_df$Z2[edges[,1]], yend=mean_df$Z2[edges[,2]], prob=(mean_df$prob[edges[,1]]+mean_df$prob[edges[,2]])/2,send=edges[,1],rec=edges[,2])#
 if(nrow(edges) != 0) edge_df_tr$Block <- k#
 all_edge_df_tr <- rbind(all_edge_df_tr, edge_df_tr)#
}#
#
#set up indicators of how many blocks a person is in#
bshape=rep(NA,nrow(all_mean_df2_tr))#
nshows=table(all_mean_df2_tr$node)#
for(nn in 1:length(bshape)){#
	ntmp=all_mean_df2_tr$node[nn]#
	bshape[nn]<-nshows[names(nshows)==as.character(ntmp)]#
}#
#
(g<-ggplot(all_mean_df2_tr) +#
 geom_segment(data=all_edge_df_tr, aes(x=x, xend=xend, y=y, yend=yend, alpha=prob/2)) +#
  guides(alpha=FALSE)+#
 geom_point(aes(Z1, Z2, alpha=prob,color=as.factor(castesubcaste),pch=as.factor(bshape),cex=1.1)) +#
  guides(cex=FALSE)+#
 #geom_text(aes(label=node, x=Z1, y=Z2, size=prob)) +#
 theme_bw() +#
 facet_wrap(~Block, nrow=2, scales='free') +#
  #labs(x="First latent dimension",y="Second latent dimension")+#
 coord_fixed(ratio=1) +#
 scale_color_manual(name="HH Caste", values=c(1:6), labels=c("General", "Minority", "OBC", "Schedule caste", "Schedule tribe", "Unknown")) +#
 scale_shape_manual(name="Block inclusion", values=c(16,17,15), labels=c("Single block", "Two Blocks", "Multiple Blocks"))+#
theme(axis.title=element_blank(), panel.grid=element_blank(), strip.background=element_blank()))#
#theme(axis.text=element_blank(), axis.ticks=element_blank(), axis.title=element_blank(), panel.grid=element_blank(), strip.background=element_blank()))#
ggsave(paste(prefix,'latent_positions_shaded.png',sep=''), g, width=4.5, height=2.5, units='in', scale=1.5)#
######################################################shaded by probabilty#
## Posteriors of global parameters#
hpd_mu <- HPDregionplot(mcmc(mcmc_samples$mu))#
hpd <- data.frame(x=hpd_mu[[1]]$x, y=hpd_mu[[1]]$y)#
#
hpd_blocks <- NULL#
for(k in 1:K) {#
  hpd_k <- HPDregionplot(mcmc(cbind(mcmc_samples$beta[,k], log(mcmc_samples$sigma[,k]))))#
  for(i in 1:length(hpd_k)) hpd_blocks <- rbind(hpd_blocks, data.frame(x=hpd_k[[i]]$x, y=hpd_k[[i]]$y, Block=paste(k), group=paste(k, i)))#
}#
#
block_params <- ldply(1:K, function(k) data.frame(beta=mcmc_samples$beta[,k], logsigma=log(mcmc_samples$sigma[,k]), Block=k))#
mean_block_params <- ddply(block_params, .(Block), summarise, beta=mean(beta), logsigma=mean(logsigma))#
#
## HPD of block-level parameters and global mean parameters - Figure 2#
#
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank()))#
ggsave(paste(prefix,'posterior_parameters.png',sep=''), g, width=4.5, height=2.5, units='in', scale=1.5)#
#
## Density plots of block-specific parameters ## NOT USED IN PAPER#
#
# ggplot(block_params) +#
  # geom_density2d(aes(beta, logsigma)) +#
  # geom_point(data=mean_block_params, aes(beta, logsigma), color='red') +#
  # facet_wrap(~Block, nrow=2) +#
  # xlab(expression(beta)) +#
  # ylab(expression(log(sigma))) +#
  # theme_bw() +#
  # geom_density2d(data=data.frame(beta=mcmc_samples$mu[,1], logsigma=mcmc_samples$mu[,2]), aes(beta, logsigma), color='black') +#
  # theme(strip.background=element_blank())#
# ggsave(paste(prefix,'posterior_parameters2.png',sep=''), g, width=4.5, height=2.5, units='in', scale=1.5)#
#
# ## Global mean samples and posterior density ## NOT USED IN PAPER#
#
# ggplot(data.frame(mcmc_samples$mu)) +#
  # geom_point(data=data.frame(mcmc_samples$mu[sample(1:nrow(mcmc_samples$mu), 1000, replace=FALSE),]), aes(X1, X2), alpha=.5) +#
  # geom_density2d(aes(X1, X2)) +#
  # geom_path(data=hpd, aes(x,y), col='red') +#
  # xlab(expression(mu[1])) +#
  # ylab(expression(mu[2])) +#
  # geom_point(x=mean(mcmc_samples$mu[,1]), y=mean(mcmc_samples$mu[,2]), col='red') +#
  # theme_bw()#
# ggsave(paste(prefix,'posterior_parameters3.png',sep=''), g, width=4.5, height=2.5, units='in', scale=1.5)#
#
## Computations presented in paper#
#
mean(mcmc_samples$beta[,1] < mcmc_samples$mu[,1])#
mean(mcmc_samples$beta[,2] < mcmc_samples$mu[,1])#
mean(mcmc_samples$beta[,3] < mcmc_samples$mu[,1])#
mean(mcmc_samples$beta[,4] < mcmc_samples$mu[,1])#
mean(mcmc_samples$beta[,5] < mcmc_samples$mu[,1])#
if(Khat==6){mean(mcmc_samples$beta[,6] < mcmc_samples$mu[,1])}#
#
mean(log(mcmc_samples$sigma[,1]) < mcmc_samples$mu[,2])#
mean(log(mcmc_samples$sigma[,2]) < mcmc_samples$mu[,2])#
mean(log(mcmc_samples$sigma[,3]) < mcmc_samples$mu[,2])#
mean(log(mcmc_samples$sigma[,4]) < mcmc_samples$mu[,2])#
mean(log(mcmc_samples$sigma[,5]) < mcmc_samples$mu[,2])#
if(Khat==6){mean(log(mcmc_samples$sigma[,6]) < mcmc_samples$mu[,2])}
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank()))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(values=c("solit", "dashed")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(values=c("solit", "dashed"),label=c("a","b")))
hpd_blocks
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group),linetype=cond) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(values=c("solit", "dashed"),label=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(values=c("solid", "dashed"),label=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(values=c("solid", "dashed"),labels=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(values=c("solid", "dashed"),labels=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(name="linetype",values=c("solid", "dashed"),labels=c("a","b"))+#
   scale_shape_manual(values=c(1,3),labels=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  #scale_linetype_manual(name="linetype",values=c("solid", "dashed"),labels=c("a","b"))+#
   scale_shape_manual(values=c(1,3),labels=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
  scale_linetype_manual(name="linetype",values=c(1,2),labels=c("a","b"))+#
   scale_shape_manual(values=c(1,3),labels=c("a","b")))
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank())+#
 guides(colour=guide_legend(override.aes=list(linetype=c(2,rep(1,times=9))))) )
(g <- ggplot(hpd_blocks) +#
  geom_path(aes(x=x, y=y, group=group)) +#
  geom_point(data=mean_block_params, aes(beta, logsigma)) +#
  xlab(expression(beta)) +#
  ylab(expression(log(sigma))) +#
  facet_wrap(~Block, nrow=2) +#
  geom_path(data=hpd, aes(x,y), linetype=2) +#
  geom_point(x=mean(mcmc_samples$beta), y=mean(log(mcmc_samples$sigma)), shape=2) +#
  theme_bw() +#
  theme(strip.background=element_blank()))
